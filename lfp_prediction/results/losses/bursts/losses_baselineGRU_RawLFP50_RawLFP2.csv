epoch,training loss,validation loss
0,7.114443086786196,0.4550440697930753
1,3.669039267580956,0.3583208550699055
2,2.6823579982155934,0.2702061702730134
3,2.394892224459909,0.2645931610604748
4,2.349363457527943,0.25834478018805385
5,2.2938272522296757,0.25411855475977063
6,2.271522409748286,0.2522354159737006
7,2.2550579329254106,0.250440955394879
8,2.2412840652978048,0.24926429253537208
9,2.233880301238969,0.2487087653717026
10,2.230087541276589,0.24838687921874225
11,2.2276494570542127,0.24815652752295136
12,2.225746789132245,0.24796163686551154
13,2.2240509048569947,0.24778010288719088
14,2.2224337743828073,0.247603522031568
15,2.2208492185454816,0.24742931604851037
16,2.219289564411156,0.24725827295333147
17,2.217773776501417,0.24709404329769313
18,2.216342961182818,0.24694222339894623
19,2.215043780161068,0.24680722376797348
