epoch,training loss,validation loss
0,0.38654160873556975,0.03502025945635978
1,0.30800784679013304,0.034573694414575584
2,0.29588785917439964,0.03204556668060832
3,0.2823384195653489,0.031027435077703558
4,0.27582302325754426,0.030334864946780726
5,0.2741772870795103,0.030228415387682617
6,0.27308492256270256,0.030157897039316595
7,0.272217441975954,0.03018841298762709
8,0.2716017702477984,0.030188770673703402
9,0.2710709285165649,0.030131185179925524
10,0.27065663288522046,0.030094829620793462
11,0.27035760966100497,0.03003400242596399
12,0.2700861657431233,0.02998316750745289
13,0.26983154535264475,0.02993124589556828
14,0.26960275416786317,0.029909135511843488
15,0.2693771812482737,0.029912876256275922
16,0.2691674691232038,0.029907830932643265
17,0.26898128742323024,0.02990337110531982
18,0.26880782486114185,0.02989853850158397
19,0.2686518759583123,0.029884306059102528
