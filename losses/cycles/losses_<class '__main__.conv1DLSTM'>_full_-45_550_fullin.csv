epoch,training loss,validation loss
0,14.647272882983088,2.341393647249788
1,10.070590663701296,2.1321914568543434
2,9.35647875862196,1.9581286092288792
3,9.089215468615294,1.8737017307430506
4,8.946331060491502,1.8334425650537014
5,8.831620764452964,1.910346123855561
6,8.715946773067117,2.107368207536638
7,8.625046050641686,1.813147060573101
8,8.584627608768642,1.9454526118934155
9,8.56019889516756,1.7595483711920679
10,8.506247239653021,1.8060256950557232
11,8.381171916611493,1.7656958745792508
12,8.35706576751545,1.8680320319253951
13,8.36369412112981,1.7578636426478624
14,8.363881025463343,1.7811365383677185
15,8.300440699793398,1.7449799480382353
16,8.23189516318962,1.734071226324886
17,8.195037675090134,1.7268721051514149
18,8.17669257381931,1.72148472443223
19,8.137638873420656,1.7191707785241306
20,8.015682223718613,1.7326101518701762
21,8.072922726161778,1.7289935159496963
22,8.084629187826067,1.7838143450208008
23,8.111607796046883,1.7169322322588414
24,8.080532159190625,1.6811968609690666
25,7.972808206919581,1.722239471040666
26,8.045565198175609,1.672539877705276
27,7.940735779237002,1.6825440465472639
28,7.965686643496156,1.6936103999614716
29,8.007167164236307,1.6722431546077132
30,7.85886123823002,1.6603426323272288
31,7.960573047399521,1.7086455840617418
32,7.93699585320428,1.7076880685053766
33,7.938091479241848,1.7087154700420797
34,7.959499585442245,1.6664798087440431
35,7.870467239525169,1.6591709379572421
36,7.887506676837802,1.6644424977712333
37,7.862516536843032,1.7090585883706808
38,7.94931069156155,1.6914513749070466
39,7.948450546246022,1.707507170503959
