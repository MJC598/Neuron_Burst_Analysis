epoch,training loss,validation loss
0,0.4301132731779944,0.028933233814314008
1,0.25508357360376976,0.027938395680394024
2,0.25119764340342954,0.027796188165666535
3,0.2504645369190257,0.02779066059156321
4,0.24984114251856226,0.027737269701901823
5,0.24882023462851066,0.02763335223426111
6,0.24788142091711052,0.027528247330337763
7,0.24580422637518495,0.027193679285119288
8,0.24045791642856784,0.026381447838502936
9,0.2345999938697787,0.025865006537060253
10,0.23159108358959202,0.02566258396836929
11,0.23017250689736102,0.025603542817407288
12,0.22925394085177686,0.02554167978814803
13,0.22861060858122073,0.02548256611044053
14,0.2281052721082233,0.025400405167602003
15,0.22763276072510052,0.025364878441905603
16,0.22715690387121867,0.0253010660817381
17,0.22661140911804978,0.02525221958057955
18,0.22606619658472482,0.025237093184841797
19,0.22560625481128227,0.025233143285731785
