epoch,training loss,validation loss
0,11.696969927637838,0.40634605707600713
1,3.4942521704360843,0.35900379135273397
2,2.795554988551885,0.2879644916392863
3,2.5193924279883504,0.2763341934187338
4,2.4549096489790827,0.2717203738866374
5,2.4221991680096835,0.268980557564646
6,2.400241221883334,0.26720029255375266
7,2.3859186433255672,0.2661977377720177
8,2.376872500171885,0.2656116794096306
9,2.3703984181629494,0.2652888499433175
10,2.3651458588428795,0.26499695738311857
11,2.3605961210560054,0.2641047443030402
12,2.3559887738665566,0.2631657144520432
13,2.350521266576834,0.2629740044940263
14,2.343373390729539,0.2624137786915526
15,2.3309924523346126,0.25968636316247284
16,2.292169856489636,0.25490695238113403
17,2.269318070146255,0.25355701602529734
18,2.262212862726301,0.2530436599627137
19,2.257390667218715,0.25254748738370836
20,2.25233428995125,0.2520499104866758
21,2.2478079753927886,0.25174497556872666
22,2.2444000863470137,0.25154058600310236
23,2.241439212230034,0.2513013924472034
24,2.2384134613675997,0.25100004742853343
25,2.2351600097026676,0.25066017999779433
26,2.2318021843675524,0.2503285682760179
27,2.2285930587677285,0.2500302763655782
28,2.225714905653149,0.24978410289622843
29,2.2232290958054364,0.24958534084726125
