epoch,training loss,validation loss
0,0.4576198653958272,0.038154694077093154
1,0.31869303731946275,0.034383420075755566
2,0.2920319417899009,0.032189782767090946
3,0.2778793069301173,0.030681222531711683
4,0.26691835015662946,0.0295556187920738
5,0.2579253457952291,0.028628928383113816
6,0.25043631202424876,0.027877138723852113
7,0.2440866081014974,0.027164913451997563
8,0.2385799677867908,0.026559794845525175
9,0.23353108296578284,0.026052075816551223
10,0.22912612577783875,0.02557064880966209
11,0.22530785413982812,0.025122707156697288
12,0.22199447962339036,0.024738014384638518
13,0.2191917356394697,0.02432426878658589
14,0.2166176152677508,0.023878532054368407
15,0.21430679503828287,0.023517321635154076
16,0.21239732264075428,0.023182082921266556
17,0.21054531828849576,0.02287771699775476
18,0.2087698659306625,0.02268006218946539
19,0.20719476304657292,0.0225083550758427
