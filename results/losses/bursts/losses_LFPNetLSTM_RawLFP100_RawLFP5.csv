epoch,training loss,validation loss
0,38.695461477153,0.4075739763211459
1,3.670827839523554,0.4075233959592879
2,3.6707021879265085,0.40783687215298414
3,3.6695091406581923,0.40858801978174597
4,3.6606326636392623,0.406230119173415
5,3.6035540989832953,0.3915435498347506
6,3.40705466887448,0.3718731857370585
7,3.323117617983371,0.3649702937109396
8,3.136578395147808,0.34076016093604267
9,3.0675030529964715,0.33976346894633025
10,3.0616601473884657,0.3392390455119312
11,3.0563363505061716,0.3386602293467149
12,3.050603872863576,0.3380291116191074
13,3.0440567672485486,0.33730135136283934
14,3.0359447373775765,0.33634988020639867
15,3.0253270589746535,0.3354421666590497
16,3.008209189400077,0.3341515390202403
17,2.9717930388869718,0.3289651615777984
18,2.944756714394316,0.32718292344361544
19,2.9350301093654707,0.32669534301385283
20,2.929373035673052,0.3263062029145658
21,2.925468063331209,0.3260443795006722
22,2.922588912420906,0.32584208506159484
23,2.920212033437565,0.32557530724443495
24,2.918181012501009,0.3253184088971466
25,2.916346293524839,0.32515731372404844
26,2.9146690745837986,0.32501750462688506
27,2.9131149012828246,0.3247767877765
28,2.911705322447233,0.3245519248303026
29,2.910443880246021,0.3243447009008378
