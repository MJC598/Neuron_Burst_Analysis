epoch,training loss,validation loss
0,1.1250173262087628,0.12547427078243345
1,1.1092690543737262,0.1226726143504493
2,1.1070308643975295,0.12266581924632192
3,1.1060140412882902,0.12244829820701852
4,1.105002640048042,0.12240330717759207
5,1.1043702330207452,0.12275460956152529
6,1.1038940731668845,0.12303617811994627
7,1.1035209356923588,0.12285837507806718
8,1.1032178744208068,0.12262519629439339
9,1.1029546404024586,0.1224889819859527
10,1.1027309350320138,0.12239293358288705
11,1.1025401631486602,0.12231678707757965
12,1.1023716130293906,0.12227898085257038
13,1.10221847781213,0.12227941467426717
14,1.1020791413029656,0.1222995949210599
15,1.1019527674652636,0.1223214955534786
16,1.1018381937174127,0.12233627622481436
17,1.1017341290134937,0.12234394811093807
18,1.1016390593140386,0.12234709516633302
19,1.1015515268663876,0.12234733218792826
