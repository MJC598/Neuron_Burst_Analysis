epoch,training loss,validation loss
0,0.7410571179489742,0.19472862558905035
1,1.8935966168420748e-06,0.1947244395269081
2,2.839384506958531e-06,0.1947005456313491
3,6.506499899056051e-06,0.19466655980795622
4,1.580188260700416e-05,0.19437957485206425
5,1.496595972631104e-05,0.1944257915019989
6,1.3083140660424819e-05,0.19392224110197276
7,1.2052414120541921e-05,0.19410835590679199
8,1.0905159200949588e-05,0.1938976098317653
9,9.731528921336219e-06,0.19391938985791057
10,8.696667481392084e-06,0.19385132938623428
11,7.919539125260389e-06,0.19372775964438915
12,7.053315909097413e-06,0.19366614613682032
13,6.345861029821709e-06,0.19354961346834898
14,5.807748695310644e-06,0.19364526006393135
15,5.238628016934754e-06,0.19363424379844218
16,4.71707666217791e-06,0.19360752287320793
17,4.292752922359366e-06,0.19359772803727537
18,3.831380223515146e-06,0.19356735865585506
19,3.580699402525034e-06,0.19348330958746374
