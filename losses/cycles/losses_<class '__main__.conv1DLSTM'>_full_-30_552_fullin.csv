epoch,training loss,validation loss
0,5.307824228191748,1.315330098150298
1,4.434555089799687,1.0866034280043095
2,4.41304518096149,1.041843595681712
3,4.338532611262053,1.0935531740542501
4,4.2959941836306825,1.0291820508427918
5,4.344708969583735,1.081483299145475
6,4.326492908876389,1.0288444990292192
7,4.261115984758362,1.018261504592374
8,4.209960542153567,1.029008788522333
9,4.27274468052201,1.0221206445712596
10,4.250773834064603,1.0282036245334893
11,4.0925914666149765,1.0257616541348398
12,3.781954000936821,0.8499254726339132
13,3.659683513920754,0.8674800047883764
14,3.6005473979748785,0.8605873105116189
15,3.587021197308786,0.8190998911159113
16,3.541927700629458,0.8409509202465415
17,3.531681305496022,0.8312691517639905
18,3.5234518287470564,0.8293652188731357
19,3.517913724645041,0.82880069676321
20,3.4952105418778956,0.8233088518027216
21,3.487004844006151,0.8262718319892883
22,3.5224269333994016,0.833414597902447
23,3.464381697238423,0.8241036552935839
24,3.486779771046713,0.8266673033358529
25,3.4641978135332465,0.8164633400738239
26,3.4670126679120585,0.815144877647981
27,3.4450262089958414,0.817532907705754
28,3.449011290562339,0.8123565588612109
29,3.436357789672911,0.8189891792135313
30,3.431573925772682,0.8170318128541112
31,3.410347409080714,0.8092004049103707
32,3.4281539215007797,0.8079386241734028
33,3.43196594028268,0.830764984479174
34,3.442740781698376,0.812059236690402
35,3.4418089335085824,0.8147750906646252
36,3.415255204658024,0.810425263014622
37,3.428188388235867,0.8140584477223456
38,3.4153974370565265,0.8049715098459274
39,3.3967203448992223,0.8073969840770587
