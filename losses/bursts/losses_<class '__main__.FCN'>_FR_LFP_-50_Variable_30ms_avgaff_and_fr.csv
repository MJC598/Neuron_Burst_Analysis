epoch,training loss,validation loss
0,122458.23547363281,21326.405975341797
1,78440.83725738525,20115.777954101562
2,76281.5760269165,19788.491134643555
3,75366.29272460938,19625.591789245605
4,74726.98606109619,19294.327545166016
5,73864.71617889404,19299.82145690918
6,73284.06981658936,19185.346641540527
7,72903.57447814941,18889.3412399292
8,72535.221824646,19123.65438079834
9,72182.82315826416,18818.900756835938
10,71951.07070922852,18991.94956970215
11,71819.88633728027,18715.836891174316
12,71627.3882522583,18877.297370910645
13,71508.24139404297,19049.750030517578
14,71342.89599609375,18770.45408630371
15,71064.61463928223,18740.18320465088
16,70834.18397521973,18781.42974090576
17,70760.94548034668,18700.010650634766
18,70649.60822296143,18628.819046020508
19,70501.14024353027,18586.573638916016
20,70392.85815429688,18504.320106506348
21,70288.48314666748,18449.60887145996
22,70168.33547973633,18387.647758483887
23,70064.89772796631,18349.409088134766
24,70004.5813293457,18323.028617858887
25,69928.90616607666,18329.95118713379
26,69868.23587036133,18306.064445495605
27,69820.05613708496,18281.764778137207
28,69767.07740020752,18275.29522705078
29,69718.53540802002,18271.972412109375
30,69660.62749481201,18257.678924560547
31,69594.12705230713,18249.627571105957
32,69551.32167816162,18245.7939453125
33,69502.98862457275,18235.65424346924
34,69466.47016906738,18231.205055236816
35,69433.4521408081,18224.6778717041
36,69403.93013000488,18216.953086853027
37,69374.89214324951,18211.014389038086
38,69346.24862670898,18206.19075012207
39,69321.85107421875,18201.287620544434
40,69297.97118377686,18196.903175354004
41,69276.61367034912,18193.24111175537
42,69257.03301239014,18189.89958190918
43,69238.20513916016,18186.971237182617
44,69219.99182128906,18184.498008728027
45,69203.32919311523,18182.27735900879
46,69187.81611633301,18180.33201599121
47,69173.17431640625,18178.784172058105
48,69159.95149230957,18177.678329467773
49,69147.5178604126,18176.8433303833
