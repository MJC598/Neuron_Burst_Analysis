epoch,training loss,validation loss
0,2979087.401704788,730944.7137298584
1,2769310.8310108185,721579.634935379
2,2680329.963657379,692550.8251152039
3,2635477.77394104,708840.9408149719
4,2586649.255630493,665526.4337005615
5,2572831.857147217,672174.0174121857
6,2539000.7781734467,673557.4764080048
7,2513251.8075847626,657113.8323535919
8,2503258.0294418335,647669.3686294556
9,2485612.57465744,642524.1783618927
10,2473145.8805179596,649342.1530456543
11,2452755.770719528,644734.9421424866
12,2445291.251197815,640120.6383304596
13,2442986.5900039673,634977.3905220032
14,2427264.1344356537,631844.8491573334
15,2418840.8061027527,626231.4544372559
16,2414643.725107193,627950.9875125885
17,2406268.626842499,624649.7218437195
18,2392110.324695587,623064.2994060516
19,2393628.8682174683,629419.9207878113
20,2380098.224884033,619606.7464199066
21,2372478.720598221,615914.6996498108
22,2363795.7608680725,620165.3271923065
23,2364604.9869117737,615089.6966362
24,2356584.8246593475,614284.0128364563
25,2347918.6164340973,613784.2031669617
26,2348142.909023285,608383.5212631226
27,2343654.8342285156,612376.2817173004
28,2343357.5652980804,612506.101650238
29,2338669.0504379272,609292.5231189728
30,2337762.4491024017,609769.7448253632
31,2338603.1113586426,608714.3377799988
32,2327307.5076293945,607449.385761261
33,2324905.795398712,604801.2695331573
34,2320937.0924224854,606630.9371509552
35,2315240.699487686,603200.5474491119
36,2313152.9670391083,603452.4555416107
37,2312611.6716804504,603585.5800914764
38,2307559.7128162384,601446.56864357
39,2307559.9277668,600498.0858650208
40,2301852.2588157654,602410.3819389343
41,2301142.310731888,602586.2390956879
42,2301023.7799892426,601378.0635299683
43,2299037.5882930756,601455.437795639
44,2295372.2026748657,601602.6245002747
45,2296050.070789337,599673.3278846741
46,2293332.2488918304,599126.1556777954
47,2290777.1104507446,599225.3934421539
48,2289906.273628235,598971.1781234741
49,2288289.9223823547,598832.8750076294
