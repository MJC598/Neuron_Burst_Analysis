epoch,training loss,validation loss
0,0.33095269199839095,0.013530702919524629
1,0.12097090290262713,0.012863268522778526
2,0.1160500770129147,0.012505387207056629
3,0.1131822683964856,0.012549120910989586
4,0.11082646232534898,0.01250442960736109
5,0.1096224079701642,0.01250179932321771
6,0.10888718792921281,0.012588505425810581
7,0.10840125850154436,0.012644016464037122
8,0.10794590715886443,0.012637598701985553
9,0.10748574990066118,0.012401383897667984
10,0.10706895546900341,0.012112365129723912
11,0.10663240506619331,0.011967069029196864
12,0.10611890650397982,0.011848164293041918
13,0.10552045084477868,0.011741062629880616
14,0.10504288449737942,0.011891565514815738
15,0.10470563614944695,0.01203133929084288
16,0.10439927373590763,0.012003120267763734
17,0.10411174580440274,0.011929180578590604
18,0.10383473325782688,0.011870738209836418
19,0.10357924873096636,0.011819307481346186
