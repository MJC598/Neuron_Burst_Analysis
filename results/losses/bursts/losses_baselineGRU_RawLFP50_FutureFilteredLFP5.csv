epoch,training loss,validation loss
0,7.252878506435081,0.4701146921142936
1,3.857095671351999,0.4004096947610378
2,3.416646610596217,0.36870247253682464
3,3.2951753991656005,0.3669163060840219
4,3.283041028538719,0.36568107502534986
5,3.2740249049384147,0.3648765793768689
6,3.2673592005157843,0.3641670581419021
7,3.2608568459982052,0.363457930739969
8,3.254536595195532,0.36279907810967416
9,3.24886903737206,0.36223042220808566
10,3.2441336014308035,0.3617709754034877
11,3.240488832234405,0.36143290053587407
12,3.2379666956840083,0.3612095285207033
13,3.236375219305046,0.3610710946377367
14,3.235398620017804,0.3609843695303425
15,3.2347757797688246,0.3609267903957516
16,3.234350213780999,0.36088617029599845
17,3.234038815717213,0.3608563117450103
18,3.2337977595161647,0.3608337910845876
19,3.2336028481367975,0.3608163127209991
