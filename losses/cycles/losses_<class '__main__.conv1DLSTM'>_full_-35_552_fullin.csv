epoch,training loss,validation loss
0,5.333061078796163,1.073869577376172
1,4.6085558257764205,1.1066936280112714
2,4.555136319831945,1.0644043067004532
3,4.494523948989809,1.0636727155651897
4,4.4696392309851944,1.077725478215143
5,4.475319602526724,1.0897516221739352
6,4.437056438298896,1.0600974375847727
7,4.412418364547193,1.2438012065831572
8,4.427235041745007,1.0525120941456407
9,4.397749664261937,1.1347862151451409
10,4.36283002817072,1.0789948599413037
11,4.174734259955585,0.9845634177327156
12,3.8171121161431074,0.8815771555528045
13,3.6718207870144397,0.8867265270091593
14,3.6299388656043448,0.8863965248456225
15,3.593891730415635,0.869651147746481
16,3.562817360740155,0.8624774792697281
17,3.5498811760917306,0.8494277528952807
18,3.5463381758891046,0.8651888780295849
19,3.5509980618953705,0.8500554357888177
20,3.541345550213009,0.8448612340725958
21,3.5279355513630435,0.8434424706501886
22,3.5178128666011617,0.8521094913594425
23,3.501187421265058,0.8610580033855513
24,3.516517942887731,0.8606592218857259
25,3.505257674958557,0.8427679035812616
26,3.487182994838804,0.8393471977906302
27,3.4731404832564294,0.8460904079256579
28,3.4662566410843283,0.8482752036070451
29,3.4771162011893466,0.8459181457292289
30,3.4673927383264527,0.8388825471047312
31,3.4609371131518856,0.8460202680435032
32,3.4642266551963985,0.8404703581472859
33,3.4692260429728776,0.8349241379182786
34,3.465785014908761,0.8340579340001568
35,3.4448839423712343,0.8375884924316779
36,3.454406949924305,0.8415344334207475
37,3.4441178794950247,0.8524618565570563
38,3.4370647980831563,0.8346320287091658
39,3.417566552059725,0.8657502789283171
