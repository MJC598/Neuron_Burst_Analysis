epoch,training loss,validation loss
0,2.6724840607494116,0.20455826027318835
1,1.8346213346812874,0.20455972012132406
2,1.834707707283087,0.204544871696271
3,1.8347189656924456,0.20454239461105317
4,1.8346379324793816,0.20448843378107995
5,1.7037971204845235,0.17493891064077616
6,1.5606510655488819,0.17290994245558977
7,1.5527042641770095,0.17247809644322842
8,1.549620810081251,0.17225850629620254
9,1.54760618659202,0.17204143130220473
10,1.5460546610411257,0.17187550489325076
11,1.5447789593599737,0.17174591915681958
12,1.5435924992198125,0.1716271584155038
13,1.542306295945309,0.17149973777122796
14,1.5408761476865038,0.171372173121199
15,1.539527016459033,0.17127071635331959
16,1.5384412332205102,0.17119588947389275
17,1.5375608901958913,0.17113176744896919
18,1.5367716236505657,0.17106199695263058
19,1.5359713922953233,0.17097983229905367
20,1.5350525135872886,0.17088156146928668
21,1.533974776393734,0.1707763341255486
22,1.5329878575867042,0.17070396861527115
23,1.5322876796126366,0.17066544201225042
24,1.531767291831784,0.1706437251996249
25,1.5313251898624003,0.17062192352022976
26,1.5309181937482208,0.17059104377403855
27,1.5305336241144687,0.17055993189569563
28,1.53016874298919,0.17053307523019612
29,1.5298207217128947,0.17050699249375612
