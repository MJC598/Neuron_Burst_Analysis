epoch,training loss,validation loss
0,0.016289974318775116,0.15651125309523195
1,0.0002617529272335075,0.16197867435403168
2,0.00012982534706088011,0.16732686816249043
3,8.544118252429289e-05,0.16167489648796618
4,7.393879430062089e-05,0.15943771821912378
5,6.268476126895794e-05,0.15681629604659975
6,8.696087370849148e-05,0.15590183180756867
7,3.988180313817258e-05,0.15679347224067897
8,3.708482774232233e-05,0.1561689048539847
9,3.336952308215929e-05,0.1553370461333543
10,2.7438819670336234e-05,0.1553654174786061
11,2.4814742266093814e-05,0.15525310742668808
12,2.17182029987259e-05,0.1550497063435614
13,1.9747942650119935e-05,0.15463694697245955
14,1.666297129513522e-05,0.15429320628754795
15,1.4805872197600281e-05,0.15402384451590478
16,1.3095535172509033e-05,0.15360567858442664
17,1.1935341161945293e-05,0.15347065462265164
18,1.0568249709040634e-05,0.15328429453074932
19,9.500829589186369e-06,0.15337416355032474
