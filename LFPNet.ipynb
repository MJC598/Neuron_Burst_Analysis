{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "COLAB_PRE = 'Neuron_Burst_Analysis/'\n",
    "if RunningInCOLAB:\n",
    "    !git clone https://github.com/MJC598/Neuron_Burst_Analysis.git\n",
    "    paths.LOSS_FILE = COLAB_PRE + paths.LOSS_FILE\n",
    "    paths.PATH = COLAB_PRE + paths.PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "import random\n",
    "import time\n",
    "import pandas as pds\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import copy\n",
    "\n",
    "from utils import preprocess, metrics\n",
    "from config import params, paths\n",
    "from models import LFPNet\n",
    "\n",
    "s = 67\n",
    "\n",
    "rs = RandomState(MT19937(SeedSequence(s)))\n",
    "rng = default_rng(seed=s)\n",
    "torch.manual_seed(s)\n",
    "\n",
    "plt.rcParams.update({'font.size': 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,save_filepath,training_loader,validation_loader,epochs,device):\n",
    "    epochs_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    training_len = len(training_loader.dataset)\n",
    "    validation_len = len(validation_loader.dataset)\n",
    "    \n",
    "#     feedback_arr = torch.zeros(params.BATCH_SIZE, 90)\n",
    "    \n",
    "    #splitting the dataloaders to generalize code\n",
    "    data_loaders = {\"train\": training_loader, \"val\": validation_loader}\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_func = nn.MSELoss()\n",
    "#     loss_func = nn.L1Loss()\n",
    "    decay_rate = 0.98 #decay the lr each step to 98% of previous lr\n",
    "    lr_sch = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "\n",
    "    total_start = time.time()\n",
    "\n",
    "    \"\"\"\n",
    "    You can easily adjust the number of epochs trained here by changing the number in the range\n",
    "    \"\"\"\n",
    "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "        start = time.time()\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        temp_loss = 100000000000000.0\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, (x, y) in enumerate(data_loaders[phase]):\n",
    "                if params.RECURRENT_NET:\n",
    "                    x = torch.transpose(x, 2, 1)\n",
    "                x = x.to(device)\n",
    "                output = model(x)\n",
    "                y = y.to(device)\n",
    "#                 if i%100000 == 0 and epoch%5 == 0:\n",
    "#                     print(output)\n",
    "#                     print(y)\n",
    "                loss = loss_func(torch.squeeze(output), torch.squeeze(y)) \n",
    "                #backprop             \n",
    "                optimizer.zero_grad()\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "#                     if i%100000 == 0 and epoch%5 == 0:\n",
    "#                         print(model.cn1.weight.grad)\n",
    "#                         print(model.cn2.weight.grad)\n",
    "#                         print(model.fc1.weight.grad)\n",
    "#                         print(model.fc2.weight.grad)\n",
    "\n",
    "                #calculating total loss\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss\n",
    "                lr_sch.step()\n",
    "            else:\n",
    "                val_loss = running_loss\n",
    "\n",
    "        end = time.time()\n",
    "        # shows total loss\n",
    "        if epoch%5 == 0:\n",
    "            print('[%d, %5d] train loss: %.6f val loss: %.6f' % (epoch + 1, i + 1, train_loss, val_loss))\n",
    "#         print(end - start)\n",
    "        \n",
    "        #saving best model\n",
    "        if train_loss < temp_loss:\n",
    "            torch.save(model, save_filepath)\n",
    "            temp_loss = train_loss\n",
    "        epochs_list.append(epoch)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "    total_end = time.time()\n",
    "#     print(total_end - total_start)\n",
    "    #Creating loss csv\n",
    "    loss_df = pds.DataFrame(\n",
    "        {\n",
    "            'epoch': epochs_list,\n",
    "            'training loss': train_loss_list,\n",
    "            'validation loss': val_loss_list\n",
    "        }\n",
    "    )\n",
    "    # Writing loss csv, change path to whatever you want to name it\n",
    "    \n",
    "    loss_df.to_csv(paths.LOSS_FILE, index=None)\n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tr, f_va = preprocess.get_inVivo_LFP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_tr, f_va, f_data = preprocess.get_filteredLFP()\n",
    "# f_tr, f_va, f_data = get_rawLFP()\n",
    "# f_tr, f_va, t_filt, v_filt = preprocess.get_end1D()#f_data, t_filt, v_filt, f_filt = get_end1D()\n",
    "\n",
    "# f_tr, f_va, f_data = preprocess.get_rawLFP()\n",
    "\n",
    "\n",
    "# noise = get_WN(channels=2)\n",
    "# sin = get_sin()\n",
    "\n",
    "# burst, fburst = preprocess.get_burstLFP()\n",
    "\n",
    "# Turn datasets into iterable dataloaders\n",
    "train_loader = DataLoader(dataset=f_tr,batch_size=params.BATCH_SIZE, shuffle=True)\n",
    "# tfilt_loader = DataLoader(dataset=t_filt,params.BATCH_SIZE=params.BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=f_va,batch_size=params.BATCH_SIZE)\n",
    "# vfilt_loader = DataLoader(dataset=v_filt,params.BATCH_SIZE=params.BATCH_SIZE)\n",
    "\n",
    "# full_loader = DataLoader(dataset=f_data,batch_size=params.BATCH_SIZE)\n",
    "\n",
    "# ffull_loader = DataLoader(dataset=f_filt,params.BATCH_SIZE=params.BATCH_SIZE)\n",
    "# noise_loader = DataLoader(dataset=noise,params.BATCH_SIZE=params.BATCH_SIZE)\n",
    "# sine_loader = DataLoader(dataset=sin,params.BATCH_SIZE=params.BATCH_SIZE)\n",
    "\n",
    "# burst_loader = DataLoader(dataset=burst,params.BATCH_SIZE=params.BATCH_SIZE)\n",
    "# fburst_loader = DataLoader(dataset=fburst,params.BATCH_SIZE=params.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = params.MODEL(params.INPUT_SIZE,params.HIDDEN_SIZE,params.OUTPUT_SIZE)\n",
    "# model1 = torch.load(paths.PATH)\n",
    "model_initial = copy.deepcopy(model1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1.to(device)\n",
    "# for name, param in model1.named_parameters():\n",
    "#     print(name)\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# model1.rnn.weight_ih_l0.requires_grad = True\n",
    "# model1.rnn.weight_hh_l0.requires_grad = True\n",
    "# model1.rnn.bias_ih_l0.requires_grad = True\n",
    "# model1.rnn.bias_hh_l0.requires_grad = True\n",
    "\n",
    "# model1.convs2k3.weight.requires_grad = True\n",
    "# model1.convs2k3.bias.requires_grad = True\n",
    "# model1.dilation.weight.requires_grad = True\n",
    "# model1.dilation.bias.requires_grad = True\n",
    "# model1.convs1k5.weight.requires_grad = True\n",
    "# model1.convs1k5.bias.requires_grad = True\n",
    "# model1.convs1k3.weight.requires_grad = True\n",
    "# model1.convs1k3.bias.requires_grad = True\n",
    "\n",
    "pnfr_training_loss, pnfr_validation_loss = train_model(model1,paths.PATH,train_loader,\n",
    "                                                       val_loader,params.EPOCHS,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(paths.PATH)\n",
    "model1.eval()\n",
    "\n",
    "start = 10\n",
    "k = 10\n",
    "end= (start + k) if k != None else None\n",
    "\n",
    "model1.to('cpu')\n",
    "\n",
    "t_pred, t_real = metrics.r2_eval(model1, train_loader, k=end)\n",
    "v_pred, v_real = metrics.r2_eval(model1, val_loader, k=end)\n",
    "\n",
    "# f_pred, f_real = r2_eval(model1, full_loader,filt=ffull_loader, k=end)\n",
    "# print(f_real)\n",
    "# t_pred, t_real = r2_eval(model1, train_loader, filt=None ,k=end)\n",
    "# v_pred, v_real = r2_eval(model1, val_loader, filt=None, k=end)\n",
    "# f_pred, f_real = r2_eval(model1, full_loader,filt=None, k=end)\n",
    "# n_pred, n_real = r2_eval(model1, noise_loader, end)\n",
    "# s_pred, s_real = r2_eval(model1, sine_loader, end)\n",
    "\n",
    "# b_pred, b_real = r2_eval(model1, burst_loader, filt=fburst_loader,k=end)\n",
    "\n",
    "# for i in range(len(s_pred)):\n",
    "#     print(\"output: {} label: {}\".format(s_pred[i], s_real[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train MSE: {:f}\".format(mean_squared_error(t_real, t_pred)))\n",
    "print(\"Val MSE: {:f}\".format(mean_squared_error(v_real, v_pred)))\n",
    "# print(\"Full MSE: {:f}\".format(mean_squared_error(f_real, f_pred)))\n",
    "# print(\"Burst MSE: {:f}\".format(mean_squared_error(b_real, b_pred)))\n",
    "print(t_real.shape)\n",
    "print(t_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, vp, tr, vr = t_pred, v_pred, t_real, v_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(iter(train_loader))[0][:,2,0])\n",
    "# print(next(iter(burst_loader))[0][:,2,0])\n",
    "t_pred = tp[:,0]\n",
    "v_pred = vp[:,0]\n",
    "t_real = tr[:,0]\n",
    "v_real = vr[:,0]\n",
    "print(t_pred.shape)\n",
    "print(t_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=1, ncols=2)\n",
    "fig1.tight_layout()\n",
    "ax1[0].plot(range(params.EPOCHS), pnfr_training_loss)\n",
    "ax1[0].set_title('Training Loss')\n",
    "ax1[0].set_ylabel('Loss')\n",
    "ax1[0].set_xlabel('Epoch')\n",
    "\n",
    "ax1[1].plot(range(params.EPOCHS), pnfr_validation_loss)\n",
    "ax1[1].set_title('Validation Loss')\n",
    "ax1[1].set_ylabel('Loss')\n",
    "ax1[1].set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[0].plot(np.arange(0,end), v_real[0:end], color='blue',label='Labels')\n",
    "# ax[2,0].plot(np.arange(start-10,end), v_output_list[start-10:end,2], color='red',label='Internal Loop')\n",
    "print(np.arange(0,end).shape, v_pred[:end].shape)\n",
    "ax[0].scatter(np.arange(0,end), v_pred[:end], color='slateblue',label='Predicted t+1')\n",
    "# ax[0].scatter(np.arange(start-params.OUTPUT_SIZE,end), v_pred[start-2:end+8,1], color='lightsteelblue',label='Training t+2')\n",
    "# ax[0].scatter(np.arange(start-params.OUTPUT_SIZE,end), v_pred[start-3:end+7,2], color='gray',label='Training t+3')\n",
    "# ax[0].scatter(np.arange(start-params.OUTPUT_SIZE,end), v_pred[start-4:end+6,3], color='sienna',label='Training t+4')\n",
    "# ax[0].scatter(np.arange(start-params.OUTPUT_SIZE,end), v_pred[start-5:end+5,4], color='magenta',label='Training t+5')\n",
    "# ax[0].scatter(np.arange(start-10,end), v_pred[start-6:end+4,5], color='aquamarine',label='Training t+6')\n",
    "# ax[0].scatter(np.arange(start-10,end), v_pred[start-7:end+3,6], color='darkorange',label='Training t+7')\n",
    "# ax[0].scatter(np.arange(start-10,end), v_pred[start-8:end+2,7], color='brown',label='Training t+8')\n",
    "# ax[0].scatter(np.arange(start-10,end), v_pred[start-9:end+1,8], color='purple',label='Training t+9')\n",
    "# ax[0].plot(np.arange(start-10,end), v_pred[start-10:end], color='green',label='Training t+10')\n",
    "\n",
    "\n",
    "ax[0].set_title('Validation LFPNet')\n",
    "ax[0].set_ylabel('LFP')\n",
    "ax[0].set_xlabel('Time')\n",
    "# ax[2,0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(0,end), t_real[:end], color='blue',label='Labels')\n",
    "# a[2,1].plot(np.arange(start-10,end), t_output_list[start-10:end,2], color='red',label='Internal Loop')\n",
    "ax[1].scatter(np.arange(0,end), t_pred[:end], color='slateblue',label='Training t+1')\n",
    "# ax[1].scatter(np.arange(start-params.OUTPUT_SIZE,end), t_pred[start-2:end+8,1], color='lightsteelblue',label='Training t+2')\n",
    "# ax[1].scatter(np.arange(start-params.OUTPUT_SIZE,end), t_pred[start-3:end+7,2], color='gray',label='Training t+3')\n",
    "# ax[1].scatter(np.arange(start-params.OUTPUT_SIZE,end), t_pred[start-4:end+6,3], color='sienna',label='Training t+4')\n",
    "# ax[1].scatter(np.arange(start-params.OUTPUT_SIZE,end), t_pred[start-5:end+5,4], color='magenta',label='Training t+5')\n",
    "# ax[1].scatter(np.arange(start-10,end), t_pred[start-6:end+4,5], color='aquamarine',label='Training t+6')\n",
    "# ax[1].scatter(np.arange(start-10,end), t_pred[start-7:end+3,6], color='darkorange',label='Training t+7')\n",
    "# ax[1].scatter(np.arange(start-10,end), t_pred[start-8:end+2,7], color='brown',label='Training t+8')\n",
    "# ax[1].scatter(np.arange(start-10,end), t_pred[start-9:end+1,8], color='purple',label='Training t+9')\n",
    "# ax[1].plot(np.arange(start-10,end), t_pred[start-10:end], color='green',label='Training t+10')\n",
    "\n",
    "ax[1].set_title('Training LFPNet')\n",
    "ax[1].set_ylabel('LFP')\n",
    "ax[1].set_xlabel('Time')\n",
    "ax[0].legend(loc=2, prop={'size': 10})\n",
    "\n",
    "# import plotly.tools as tls\n",
    "# plotly_fig = tls.mpl_to_plotly(fig)\n",
    "# plotly_fig.write_html(\"testfile.html\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax.plot(np.arange(start,end), f_real[start:end], color='blue',label='Labels')\n",
    "ax.scatter(np.arange(start,end), f_pred[start:end], color='red',label='Training t+10')\n",
    "ax.set_title('Full LFP vs Time')\n",
    "ax.set_ylabel('Signal')\n",
    "ax.set_xlabel('Time')\n",
    "\n",
    "# ax[1].plot(np.arange(start,end), n_real[start:end], color='blue',label='Labels')\n",
    "# ax[1].scatter(np.arange(start,end), n_pred[start:end], color='red',label='Training t+10')\n",
    "# ax[1].set_title('Noise')\n",
    "# ax[1].set_ylabel('Signal')\n",
    "# ax[1].set_xlabel('Time')z\n",
    "\n",
    "# ax.plot(np.arange(start,end), s_real[start:end], color='blue',label='Labels')\n",
    "# ax.scatter(np.arange(start,end), s_pred[start:end], color='red',label='Training t+10')\n",
    "# ax.set_title('Sine')\n",
    "# ax.set_ylabel('LFP')\n",
    "# ax.set_xlabel('Time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "\n",
    "STEPS = 100\n",
    "# model_initial = params.MODEL(params.INPUT_SIZE,params.HIDDEN_SIZE,params.OUTPUT_SIZE)\n",
    "model_final = copy.deepcopy(model1)\n",
    "\n",
    "\n",
    "# data that the evaluator will use when evaluating loss\n",
    "x, y = iter(noise_loader).__next__()\n",
    "metric = loss_landscapes.metrics.Loss(nn.MSELoss(), x, y)\n",
    "\n",
    "\n",
    "loss_data_fin = loss_landscapes.random_plane(model_final, metric, 10000, STEPS, normalization='model', deepcopy_model=True)\n",
    "# plt.contour(loss_data_fin, levels=50)\n",
    "# plt.title('Loss Contours around Trained Model')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "X = np.array([[j for j in range(STEPS)] for i in range(STEPS)])\n",
    "Y = np.array([[i for _ in range(STEPS)] for i in range(STEPS)])\n",
    "ax.plot_surface(X, Y, loss_data_fin, rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Surface Plot of Loss Landscape')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.state_dict()['conv_block.0.weight'])\n",
    "print(model1.state_dict()['conv_block.0.bias'])\n",
    "print(model1.state_dict()['conv_block.2.weight'])\n",
    "print(model1.state_dict()['conv_block.2.bias'])\n",
    "print(model1.state_dict()['ck1s1.weight'])\n",
    "print(model1.state_dict()['ck1s1.bias'])\n",
    "print(model1.state_dict()['fc1.weight'])\n",
    "print(model1.state_dict()['fc1.bias'])\n",
    "print(model1.state_dict()['fc2.weight'])\n",
    "print(model1.state_dict()['fc2.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
