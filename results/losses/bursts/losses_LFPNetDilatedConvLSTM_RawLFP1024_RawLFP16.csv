epoch,training loss,validation loss
0,2.672484066686593,0.20455825934186578
1,1.8346213339827955,0.20455971965566278
2,1.8347077034413815,0.20454487157985568
3,1.8347189665073529,0.20454239554237574
4,1.8346379323629662,0.20448843424674124
5,1.703797126072459,0.17493891378398985
6,1.560651063802652,0.17290994548238814
7,1.5527042633621022,0.1724780967924744
8,1.549620802514255,0.1722585055977106
9,1.5476061848457903,0.17204143339768052
10,1.5460546592948958,0.17187550547532737
11,1.544778959476389,0.17174591950606555
12,1.5435924918856472,0.17162715713493526
13,1.5423062989721075,0.17149973812047392
14,1.5408761468715966,0.171372173121199
15,1.5395270123844966,0.17127071460708976
16,1.5384412335697562,0.1711958886589855
17,1.5375608932226896,0.17113176709972322
18,1.5367716269101948,0.1710619975347072
19,1.5359713967191055,0.17097983451094478
20,1.535052518127486,0.17088156135287136
21,1.5339747803518549,0.17077633645385504
22,1.5329878613119945,0.17070396814960986
23,1.5322876841528341,0.1706654450390488
24,1.5317672961391509,0.17064372554887086
25,1.5313251906773075,0.17062192119192332
26,1.5309181946795434,0.1705910477321595
27,1.5305336223682389,0.17055993154644966
28,1.530168742639944,0.1705330734839663
29,1.5298207235755399,0.17050699412357062
