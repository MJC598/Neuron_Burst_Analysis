epoch,training loss,validation loss
0,0.6251826315419748,0.08908917551161721
1,0.6147552990587428,0.08731959288707003
2,0.6142566391499713,0.08540155208902434
3,0.6137176778865978,0.0854784501134418
4,0.6134496089071035,0.08567696379031986
5,0.6132278557633981,0.08588204061379656
6,0.6129759822506458,0.08582862664479762
7,0.6128147867275402,0.08568461536196992
8,0.6126261061290279,0.08560238219797611
9,0.6124710607109591,0.08520872268127277
10,0.612257813103497,0.08536623808322474
11,0.6121033813105896,0.08532624476356432
12,0.6119270733324811,0.0855096016312018
13,0.6117761743953452,0.08546197944087908
14,0.6115993651328608,0.08534486801363528
15,0.6114357868209481,0.08508666540728882
16,0.6112709282897413,0.08479710965184495
17,0.6111355434404686,0.08449068292975426
18,0.61098901508376,0.08419094019336626
19,0.6108253218699247,0.08401779021369293
