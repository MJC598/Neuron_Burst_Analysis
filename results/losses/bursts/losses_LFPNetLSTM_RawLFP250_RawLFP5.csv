epoch,training loss,validation loss
0,3.6258808464044705,0.317304705735296
1,2.570201391237788,0.2733091216068715
2,2.416620322270319,0.26529253378976136
3,2.358744115103036,0.26010655681602657
4,2.32098433165811,0.2563175514806062
5,2.289418453001417,0.2525560889625922
6,2.25752654671669,0.2489775080466643
7,2.2294863724382594,0.24622741679195315
8,2.2094600052805617,0.24453521135728806
9,2.195129713276401,0.2433820612495765
10,2.1843539751134813,0.2423442917643115
11,2.1768934855936095,0.24154523271135986
12,2.170209795120172,0.2409760960144922
13,2.16348842473235,0.2403893704758957
14,2.1579301637830213,0.2398902520071715
15,2.1528005653526634,0.2396551569690928
16,2.148274260922335,0.2388889881549403
17,2.142142583732493,0.23937817243859172
18,2.1352956752525643,0.23885429732035846
19,2.131188612547703,0.2385682261083275
20,2.128190213465132,0.23838902940042317
21,2.1255329764680937,0.23823827726300806
22,2.1231320834485814,0.23809629632160068
23,2.120919039938599,0.2379274662816897
24,2.1188886339077726,0.23778463702183217
25,2.116998683428392,0.23763948329724371
26,2.1152464881306514,0.23750293860211968
27,2.113597630755976,0.23736587236635387
28,2.1120497685624287,0.237254299223423
29,2.110591382952407,0.23715971689671278
