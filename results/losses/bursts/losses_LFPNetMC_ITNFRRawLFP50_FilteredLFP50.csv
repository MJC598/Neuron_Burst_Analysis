epoch,training loss,validation loss
0,1.3096084414282814,0.14101763482904062
1,1.2388736068387516,0.13849079451756552
2,1.2278991464409046,0.13689666287973523
3,1.2236188105889596,0.13660740858176723
4,1.2207410010742024,0.13657326227985322
5,1.2194428250659257,0.1363689603167586
6,1.2184334284393117,0.1362718780292198
7,1.217445308691822,0.13622167927678674
8,1.2166844759485684,0.13617450883612037
9,1.216117897827644,0.13614119653357193
10,1.2155762652982958,0.13613848201930523
11,1.2151361118303612,0.13611866487190127
12,1.2147259807097726,0.13608211546670645
13,1.214372418646235,0.1360889310017228
14,1.2140246139024384,0.13609164982335642
15,1.2136412829859182,0.13610289641655982
16,1.2133303920854814,0.1361191057949327
17,1.2130583348916844,0.13612395303789526
18,1.2128431859309785,0.13613423536298797
19,1.2125743668875657,0.1361391907557845
