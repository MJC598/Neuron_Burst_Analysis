epoch,training loss,validation loss
0,4.72676604683511,0.9587300687562674
1,3.740521219326183,0.8658199314959347
2,3.5913130266126245,1.0116509723011404
3,3.6333255250938237,0.8479608997004107
4,3.473078638780862,0.9445464926538989
5,3.4902074463898316,0.8551373837981373
6,3.4945977517636493,0.8603168702684343
7,3.315870210644789,0.8742419077316299
8,3.3258443934610114,0.7985173580236733
9,3.270104677998461,0.7887966302223504
10,3.235736354487017,0.8058147099800408
11,3.2117020620498806,0.7811037370702252
12,3.21789267542772,0.7727931354893371
13,3.1659653320675716,0.7985947069246322
14,3.1613513429183513,0.7924938367214054
15,3.1251543518155813,0.791371981613338
16,3.136904298211448,0.8180246452102438
17,3.1402280336478725,0.7568511710269377
18,3.1004868225427344,0.756492261774838
19,3.100668491446413,0.7563752306159586
20,3.0973585966276005,0.7679132843622938
21,3.067886112141423,0.8013564653228968
22,3.0651481284294277,0.7890288518974558
23,3.069558613700792,0.769630117691122
24,3.0521164040546864,0.7554696856532246
25,3.0532668214291334,0.7677189073292539
26,3.009735975996591,0.7548241214826703
27,3.050054984400049,0.7913037143880501
28,3.0070166185032576,0.76771784061566
29,3.0275971562368795,0.7550449940608814
30,3.0177400502143428,0.7535827530082315
31,3.037265556282364,0.7571374855469912
32,3.0002749003469944,0.7449804388452321
33,3.0116454761009663,0.7617039090255275
34,3.0184621531516314,0.7468206525081769
35,3.00923399196472,0.7443754362175241
36,3.0255669018952176,0.751985649112612
37,2.9949170615291223,0.7494686391437426
38,2.993193129193969,0.7512380497064441
39,3.015176387852989,0.7534580491483212
