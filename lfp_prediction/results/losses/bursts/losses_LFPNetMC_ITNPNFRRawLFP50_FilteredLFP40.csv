epoch,training loss,validation loss
0,1.0159728523285594,0.10460701485862955
1,0.9268405959883239,0.1028319580364041
2,0.9169040827546269,0.10236238382640295
3,0.9129669269605074,0.10204328410327435
4,0.9105673700105399,0.101920343877282
5,0.9088809667446185,0.10179634563974105
6,0.9075785703898873,0.10170227006892674
7,0.9063635926868301,0.10172477376181632
8,0.9053542037436273,0.10165456251706928
9,0.9043926047161222,0.1015992262691725
10,0.9035138459585141,0.10156709011062048
11,0.9026615731418133,0.10156344642746262
12,0.9019612143747509,0.10152602876769379
13,0.9013574180426076,0.10152278005261905
14,0.9006462336110417,0.10147589989355765
15,0.8999652407946996,0.10147154293372296
16,0.8993685926543549,0.10148196338559501
17,0.8987825960211921,0.10146029244060628
18,0.8981510408630129,0.10145979732624255
19,0.8975506953138392,0.10140972479712218
