epoch,training loss,validation loss
0,14.223859745077789,2.255107772536576
1,10.146902829408646,2.1467159572057426
2,9.867929050233215,2.2465209397487342
3,9.57479416904971,2.0677684103138745
4,9.616120757069439,2.0937509606592357
5,9.538178235292435,2.040776470210403
6,9.415865445509553,1.886751619167626
7,9.462474630214274,1.914565363433212
8,9.21125988708809,1.899138206616044
9,9.168212838936597,1.962649259250611
10,9.140194738749415,1.934578521642834
11,9.148917431011796,2.149617811664939
12,9.115315145347267,1.9244701159186661
13,9.082629695534706,1.8787467423826456
14,8.997670928947628,1.9469463718123734
15,8.965526396408677,1.9030173406936228
16,9.00365890050307,1.8853419828228652
17,8.99442462157458,1.9126651659607887
18,8.912963894661516,1.9015721641480923
19,8.996355316601694,1.906737595796585
20,8.878694160841405,1.897300174459815
21,8.868724788539112,1.8483354379422963
22,8.809233198873699,1.9123214627616107
23,8.850983620621264,1.8971098884940147
24,8.790236483793706,1.8562846956774592
25,8.69847355922684,1.844267382286489
26,8.847116706427187,1.8319828282110393
27,8.86030595889315,1.9718450917862356
28,8.788760190829635,1.8373806104063988
29,8.815635371953249,1.8681729543022811
30,8.826271819416434,1.9161749728955328
31,8.792208861093968,1.8663503150455654
32,8.752256233710796,1.8794406969100237
33,8.756522847339511,1.8354217698797584
34,8.689980248454958,1.862763316836208
35,8.728298227768391,1.8528780094347894
36,8.758649869356304,1.8835659944452345
37,8.688056387472898,1.8407474597916007
38,8.705637619830668,1.8618161310441792
39,8.703018352854997,1.8715389310382307
