epoch,training loss,validation loss
0,0.0032087066441357282,0.13051675481256098
1,6.939413210794298e-17,0.13051675795577466
2,4.393873592959693e-21,0.13051675795577466
3,4.393873592959693e-21,0.13051675795577466
4,4.393873592959693e-21,0.13051675795577466
5,4.393873592959693e-21,0.13051675795577466
6,4.393873592959693e-21,0.13051675795577466
7,4.393873592959693e-21,0.13051675807219
8,4.393873592959693e-21,0.1305167581886053
9,4.393873592959693e-21,0.13051675853785127
10,4.393873592959693e-21,0.13051675900351256
11,4.393873592959693e-21,0.13051675935275853
12,4.393873592959693e-21,0.13051675935275853
13,4.393873592959693e-21,0.13051675935275853
14,4.393873592959693e-21,0.1305167597020045
15,4.393873592959693e-21,0.1305167597020045
16,4.393873592959693e-21,0.1305167597020045
17,4.393873592959693e-21,0.13051675946917385
18,4.393873592959693e-21,0.13051675958558917
19,1.7002346685871729e-16,0.130516761331819
