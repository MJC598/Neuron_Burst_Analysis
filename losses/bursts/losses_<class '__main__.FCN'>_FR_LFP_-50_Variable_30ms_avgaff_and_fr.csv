epoch,training loss,validation loss
0,3048557.3416519165,737220.9349098206
1,2773904.045604706,702153.6939086914
2,2703320.576002121,694485.5828304291
3,2639200.1176071167,723794.2195892334
4,2610703.1650485992,665766.4422016144
5,2558882.646463394,661238.9383335114
6,2530430.9583511353,651160.3055343628
7,2516382.1679706573,649618.7661457062
8,2496301.7429065704,644648.6719608307
9,2475897.034353256,642652.9224796295
10,2446869.3739681244,644653.4425773621
11,2455702.273464203,650389.6437759399
12,2437937.4638957977,631017.1429424286
13,2432644.270669937,627886.4437713623
14,2414874.0631217957,625232.7400512695
15,2402438.409303665,634241.1246356964
16,2383116.9157657623,614816.2608680725
17,2379577.4416179657,622166.9033546448
18,2367034.110973358,616538.7261199951
19,2367912.5384311676,617085.0401115417
20,2359269.1511802673,615347.8410491943
21,2351188.358652115,615508.2152881622
22,2340233.1815395355,613384.6635513306
23,2340314.457349777,609204.7111759186
24,2334354.3148384094,611402.2739868164
25,2333556.103410721,605548.6427726746
26,2318521.006052017,606055.4187412262
27,2317090.896259308,603243.488620758
28,2311275.8763742447,602296.770898819
29,2308514.9862861633,599447.4264431
30,2300620.510614395,596472.8562602997
31,2296097.506266594,596948.2727451324
32,2296761.5528888702,600399.2470321655
33,2295552.4603157043,599845.833644867
34,2292033.619113922,599351.3954372406
35,2290563.177564621,599856.8766880035
36,2284950.4871501923,598277.6918487549
37,2283376.8291282654,596636.1976470947
38,2280189.0544786453,596067.8917541504
39,2279299.1883773804,595419.4736995697
40,2274732.1086330414,593338.0822658539
41,2272596.6592350006,594560.2059574127
42,2272319.6291923523,594024.42527771
43,2269688.6905708313,593011.6302394867
44,2268316.2968883514,593424.9859409332
45,2267168.187887192,593289.6696815491
46,2266281.573928833,592881.8754997253
47,2264618.968421936,592366.5413188934
48,2264423.481370926,591972.4118461609
49,2261978.0464019775,592021.2024669647
