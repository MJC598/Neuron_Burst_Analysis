epoch,training loss,validation loss
0,38.70808041840792,0.40837049344554543
1,3.6696782890940085,0.4082714846590534
2,3.669733729446307,0.40810426976531744
3,3.668978458386846,0.4078969700494781
4,3.6658216392388567,0.40716932876966894
5,3.648168498650193,0.4012955332873389
6,3.5114265189040452,0.3782846585381776
7,3.3572399644181132,0.3716331528266892
8,3.3146058130078018,0.36527190753258765
9,3.108787694014609,0.3430557930842042
10,3.0563576717395335,0.3403237028978765
11,3.049525394337252,0.33949820999987423
12,3.0428263233043253,0.3388395047513768
13,3.035278740338981,0.338015423505567
14,3.026089378632605,0.3369611023226753
15,3.013469678699039,0.33530914690345526
16,2.9939982892246917,0.33239098463673145
17,2.961406701710075,0.32834799005649984
18,2.9356847014278173,0.326754012145102
19,2.92758446035441,0.3261230706702918
