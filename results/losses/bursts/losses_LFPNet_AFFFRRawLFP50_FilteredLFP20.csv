epoch,training loss,validation loss
0,6.372775069612544,0.10841175843961537
1,0.5388671700347913,0.04844299078104086
2,0.41656223859172314,0.0437612386449473
3,0.37401426016003825,0.0423168086563237
4,0.3441211134486366,0.04080385679844767
5,0.32462948783359025,0.03802176233148202
6,0.3080620672990335,0.03195091357338242
7,0.2771264431721647,0.02918988982855808
8,0.26140241573011735,0.028006493514112663
9,0.2530988436556072,0.027442096892627887
10,0.24812766549439402,0.027065683614637237
11,0.24464215588523075,0.026818880840437487
12,0.24227317629993195,0.0266370776007534
13,0.24053153434215346,0.026497237726289313
14,0.2391733333861339,0.026344796337070875
15,0.2380346772406483,0.026308679007343017
16,0.23712846241687657,0.026244274304190185
17,0.2363468676849152,0.02620156152988784
18,0.23569223783852067,0.026145470248593483
19,0.2351171654954669,0.026091472085681744
