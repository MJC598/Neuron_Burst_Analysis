epoch,training loss,validation loss
0,1.9417991184163839,0.18467342958319932
1,1.5977437117835507,0.17461402632761747
2,1.5551375629147515,0.17244793195277452
3,1.5427931327139959,0.1715114942053333
4,1.5367180588655174,0.1709169327514246
5,1.532344412873499,0.1704257382079959
6,1.5284448799211532,0.16993874497711658
7,1.5242569821421057,0.16937947715632617
8,1.5193358107935637,0.16880470339674503
9,1.513934689690359,0.1682525834767148
10,1.5088600468588993,0.16770754824392498
11,1.5047530439915136,0.167280278285034
12,1.5015578733291477,0.16694810870103538
13,1.4989916179329157,0.1666842958657071
14,1.4968544190051034,0.16645777970552444
15,1.4950189320370555,0.16625705873593688
16,1.4934080854291096,0.1660781925311312
17,1.49197172827553,0.1659178719855845
18,1.4906762982718647,0.16577314375899732
19,1.4894984782440588,0.165641566272825
20,1.488421326270327,0.16552122624125332
21,1.487431596731767,0.16541068954393268
22,1.4865181980421767,0.16530881926883012
23,1.4856714783236384,0.1652146604610607
24,1.484882874879986,0.16512738331221044
25,1.4841448538936675,0.165046205278486
26,1.4834508497733623,0.16497038409579545
27,1.4827952177729458,0.16489921533502638
28,1.4821731044212356,0.16483203787356615
29,1.4815803650999442,0.16476826730649918
