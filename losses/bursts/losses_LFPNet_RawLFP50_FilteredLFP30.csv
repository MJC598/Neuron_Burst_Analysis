epoch,training loss,validation loss
0,0.2857156653772108,0.02819340315181762
1,0.25297759970999323,0.028409829799784347
2,0.25017931961338036,0.02801644170540385
3,0.24611475941492245,0.027527151367394254
4,0.2413439148076577,0.02691197450621985
5,0.23808304383419454,0.026463346934178844
6,0.2358384630351793,0.02612819198111538
7,0.23374305659672245,0.025878431348246522
8,0.23204155109124258,0.0257268941932125
9,0.23098801626474597,0.02564113595872186
10,0.23024272784823552,0.02557934683864005
11,0.22965225533698685,0.02553685737075284
12,0.22917126651736908,0.025489657404250465
13,0.22876866046863142,0.025448855580179952
14,0.22835825751826633,0.025418522869586013
15,0.2279605668882141,0.025396187076694332
16,0.22762945355498232,0.02539005398284644
17,0.22733308594615664,0.02539004092977848
18,0.22705795637739357,0.02538122185796965
19,0.2268220890837256,0.02535604096192401
