epoch,training loss,validation loss
0,38.423961982131004,0.4062050567008555
1,3.551798697328195,0.3869822770357132
2,3.4325120421126485,0.3803979931399226
3,3.4067563817370683,0.37944121519103646
4,3.3977004274493083,0.3781864148331806
5,3.3837730844970793,0.3763518593041226
6,3.366137092350982,0.3743464364670217
7,3.3498372255126014,0.372821681201458
8,3.340343513409607,0.3722384086577222
9,3.3380585024133325,0.37217544589657336
10,3.3378358804620802,0.3721604673191905
11,3.3376922372262925,0.3721440453082323
12,3.3375349894631654,0.37212714762426913
13,3.3373780511319637,0.37211086542811245
14,3.3372285088989884,0.3720956254983321
15,3.3370882913004607,0.37208139919675887
16,3.3369564942549914,0.37206799315754324
17,3.336831567226909,0.37205523368902504
18,3.3367121312767267,0.3720429837703705
19,3.3365971298189834,0.37203114619478583
