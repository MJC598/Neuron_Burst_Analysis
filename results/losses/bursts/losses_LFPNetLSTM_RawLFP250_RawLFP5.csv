epoch,training loss,validation loss
0,32.89571378857363,0.38626876566559076
1,3.3738489156821743,0.37362546590156853
2,3.306516771786846,0.37048611661884934
3,3.2876613412518054,0.3695994117297232
4,3.2822536629391834,0.36891020799521357
5,3.2800665823742747,0.368786912295036
6,3.278839419828728,0.368784777703695
7,3.2780087566934526,0.36880169284995645
8,3.2773058449383825,0.3688440821133554
9,3.276643706834875,0.36889612080994993
10,3.2760114937555045,0.36892303777858615
11,3.27539807674475,0.3689197908388451
12,3.274806394474581,0.3688854604260996
13,3.2742389150662348,0.36882234015502036
14,3.2736922996118665,0.36873581109102815
15,3.273163861827925,0.3686330287018791
16,3.272653282736428,0.3685179731110111
17,3.2721503927605227,0.3683953091967851
18,3.2716464267577976,0.3682623946806416
19,3.271126729203388,0.3681236590491608
20,3.270576141658239,0.3679763380205259
21,3.2699738980736583,0.3678195094689727
22,3.269288444542326,0.3676479272544384
23,3.2684633769094944,0.3674499918706715
24,3.267377185402438,0.36720753624103963
25,3.2657035572919995,0.3668515692697838
26,3.2620572282467037,0.3659635545918718
27,3.245504774735309,0.3610354248667136
28,3.0094695249572396,0.3181055703898892
29,2.820139958523214,0.31503708357922733
