epoch,training loss,validation loss
0,1.509681467548944,0.1650248816004023
1,1.4680364559171721,0.16471258079400286
2,1.465201814135071,0.16454831144073978
3,1.4624464406515472,0.16411342128412798
4,1.4509927241597325,0.1614319020882249
5,1.434605032147374,0.16072621807688847
6,1.4293060611817054,0.1602610944537446
7,1.4244761897134595,0.15969623875571415
8,1.4189417791203596,0.1591770068043843
9,1.4145527150831185,0.15887644444592297
10,1.411666843749117,0.15866409899899736
11,1.409528353717178,0.15849644475383684
12,1.4078140229103155,0.15836162498453632
13,1.4064094056957401,0.15825515502365306
14,1.405261654406786,0.15817030845209956
15,1.404322681715712,0.15809867571806535
16,1.403545088483952,0.15803332079667598
17,1.4028891466441564,0.1579700129223056
18,1.402324860508088,0.15790691232541576
19,1.4018304613418877,0.15784380928380415
