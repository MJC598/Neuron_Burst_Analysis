epoch,training loss,validation loss
0,0.13177723835542565,0.012777402873325627
1,0.11469021511948085,0.012779241122188978
2,0.11442746577449725,0.012725095126370434
3,0.11395247445398127,0.012756594900565688
4,0.11360616149977432,0.012698002930846997
5,0.11339512489939807,0.01270360379567137
6,0.113207269088889,0.012685914345638594
7,0.11303298634811654,0.012638332726055523
8,0.11287905478093307,0.012657572056923527
9,0.11276111843835679,0.012730131686112145
10,0.11265060155346873,0.012692376923951088
11,0.11255682585397153,0.012648521595110651
12,0.11248503615206573,0.0126402796486218
13,0.1124330665479647,0.012645100989175262
14,0.11239422238941188,0.012657385879720096
15,0.1123514823448204,0.012668495557591086
16,0.11230145407171221,0.01267397083574906
17,0.11225460639616358,0.012673375225858763
18,0.1122139082835929,0.012661641510931076
19,0.11217762198066339,0.012638277854421176
