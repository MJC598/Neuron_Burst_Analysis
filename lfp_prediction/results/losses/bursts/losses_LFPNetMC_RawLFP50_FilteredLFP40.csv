epoch,training loss,validation loss
0,1.487629722978454,0.12277414154959843
1,1.0834329319768585,0.1371852758456953
2,1.0587790143908933,0.12388746946817264
3,1.0447287730057724,0.1152074096025899
4,1.0361605667858385,0.11347911925986409
5,1.0292777807917446,0.11380742670735344
6,1.024925972771598,0.11292916646925732
7,1.0196149909461383,0.1133259124471806
8,1.0149019824166317,0.11522244062507525
9,1.0124638974375557,0.11411852441960946
10,1.010180516197579,0.11180195107590407
11,1.0065747898770496,0.11144964455161244
12,1.0025480741460342,0.1110602215921972
13,0.9977997163368855,0.11053292281576432
14,0.9927951104764361,0.11026629849220626
15,0.98841270909179,0.11017281585372984
16,0.9848442202201113,0.1097079771279823
17,0.981012645555893,0.10915043714339845
18,0.9765848503448069,0.10862740804441273
19,0.9722161725221667,0.10829061799449846
