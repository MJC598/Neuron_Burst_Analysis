epoch,training loss,validation loss
0,4.352339597127866,0.47017853683792055
1,2.062213410041295,0.37329056404996663
2,1.977831226424314,0.44749787368346006
3,1.9313629663083702,0.3980920278117992
4,1.875230071716942,0.3584659132757224
5,1.8503971961908974,0.33688358071958646
6,1.8288776050903834,0.3501647502416745
7,1.7686968197813258,0.3457197296083905
8,1.7909574115183204,0.3279005151707679
9,1.6992143380921334,0.33529370033647865
10,1.6965219539124519,0.37495230801869184
11,1.6913625654415227,0.3273936511250213
12,1.641013260523323,0.3563770854379982
13,1.6345209422288463,0.3199222374241799
14,1.620568725396879,0.3267336995340884
15,1.628546453488525,0.31484173075295985
16,1.5696672814083286,0.31795256113400683
17,1.5873354725772515,0.3520572987617925
18,1.565686738875229,0.3045118005829863
19,1.5614836406894028,0.3280082291457802
20,1.5890662371530198,0.30565241555450484
21,1.5500644344720058,0.32538469368591905
22,1.554491824703291,0.3069422412663698
23,1.6044975409167819,0.3105860374053009
24,1.501200100639835,0.3007292184047401
25,1.5237704612663947,0.30504480356466956
26,1.5248426254838705,0.3115006726584397
27,1.5157022150233388,0.30254479096038267
28,1.4847394276293926,0.3137080791639164
29,1.5057262268965133,0.30152342858491465
30,1.5117349927313626,0.3154120635590516
31,1.4857003564829938,0.29808114204206504
32,1.4702603972982615,0.2964290573145263
33,1.4863778615836054,0.2958983544376679
34,1.4498812512028962,0.2993881885195151
35,1.4560669253696688,0.3087531395140104
36,1.4990766884584446,0.31058580707758665
37,1.4816970588290133,0.29869891819544137
38,1.462365250219591,0.30068631196627393
39,1.478007656056434,0.29805057059274986
