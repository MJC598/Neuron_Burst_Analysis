epoch,training loss,validation loss
0,3.662655645632185,0.4076819533947855
1,3.6571495853131637,0.4072246600408107
2,3.6561302113113925,0.4070356987649575
3,3.6551894570002332,0.4070855265017599
4,3.654561798204668,0.40718861029017717
5,3.654137176228687,0.40727220848202705
6,3.6538119536126032,0.40739793062675744
7,3.653570489026606,0.4074981187004596
8,3.6533790739485994,0.407542142434977
9,3.6532114195870236,0.4075399220455438
10,3.6530669119674712,0.40751542325597256
11,3.652925143018365,0.40746407280676067
12,3.6527880897047,0.40738224680535495
13,3.6526415841653943,0.40730985486879945
14,3.652490926440805,0.4072394698159769
15,3.6523370310897008,0.4071928149787709
16,3.6521796599263325,0.40715997701045126
17,3.652018148684874,0.40713725227396935
18,3.6518514255294576,0.4071195023134351
19,3.651680502574891,0.40710471279453486
