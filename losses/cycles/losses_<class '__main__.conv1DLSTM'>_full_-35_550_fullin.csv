epoch,training loss,validation loss
0,14.725638476666063,3.664634531363845
1,10.382579943165183,2.294989704620093
2,9.882236887700856,2.228360883425921
3,9.74301580619067,2.398142237216234
4,9.758379007689655,2.0690612783655524
5,9.690486762207001,2.0397678911685944
6,9.58574447967112,2.006285444367677
7,9.52950879978016,2.079467749223113
8,9.327444437891245,2.02310246322304
9,9.486133544705808,1.9719664067961276
10,9.386003435589373,1.9920213529840112
11,9.443194716237485,1.996818776242435
12,9.325020520016551,1.9492249838076532
13,9.385168332606554,1.97813849337399
14,9.172312878072262,1.940092848148197
15,9.307357955724001,1.9022635715082288
16,9.08111881557852,1.9276747982949018
17,9.205582892522216,1.8907732060179114
18,9.161411904729903,1.9260626956820488
19,9.148330058902502,1.8736788029782474
20,9.041255955584347,1.8556413119658828
21,9.120990166440606,1.9180298103019595
22,9.203782261814922,1.9990634941495955
23,9.059535826090723,1.88453749101609
24,8.98760754102841,1.8696000608615577
25,8.984373410232365,1.8782245004549623
26,9.142380171921104,1.9043168011121452
27,9.131471959874034,1.895438271574676
28,8.943309277296066,1.8861028673127294
29,9.0202077627182,1.875444266013801
30,9.011046322528273,1.895956420339644
31,8.928998596966267,1.8814669321291149
32,8.921490724664181,1.8867847598157823
33,8.973709533456713,1.9020745125599205
34,8.962744100950658,1.8618663265369833
35,8.960163150914013,1.858495218679309
36,8.936948135960847,1.8693164680153131
37,8.85432803351432,1.8562263743951917
38,8.853967523667961,1.8811409124173224
39,8.948303243611008,1.8576969802379608
