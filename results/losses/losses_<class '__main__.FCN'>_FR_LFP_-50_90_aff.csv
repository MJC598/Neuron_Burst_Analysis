epoch,training loss,validation loss
0,5677183.173233032,1482512.2880477905
1,5672442.571128845,1482508.7572517395
2,5671770.922084808,1482900.5156288147
3,5670620.584831238,1482757.7928085327
4,5670804.153266907,1483168.9892921448
5,5669212.626667023,1483266.6203193665
6,5667966.035255432,1483210.5311431885
7,5667538.345561981,1482933.3960762024
8,5666488.381275177,1483776.4101486206
9,5666021.507610321,1483152.6033210754
10,5664703.82036972,1483749.5040779114
11,5664175.859134674,1483622.9384002686
12,5663166.648586273,1483405.0076942444
13,5662221.542884827,1483581.6169815063
14,5660886.479389191,1483904.4262619019
15,5659316.569316864,1484073.9888916016
16,5658033.053794861,1484177.4817619324
17,5657599.19978714,1484638.5389328003
18,5656331.947738647,1484705.4860801697
19,5655001.764671326,1484539.1271972656
20,5653745.064735413,1484518.5905723572
21,5652443.02513504,1484461.9947280884
22,5651439.523803711,1484562.6292915344
23,5650265.225063324,1484819.923488617
24,5649177.09961319,1484898.2360572815
25,5648209.055141449,1485214.229068756
26,5647157.492340088,1485358.8966712952
27,5646326.766433716,1485551.7685317993
28,5645423.540271759,1485702.756515503
29,5644582.163383484,1485822.1184692383
30,5643890.871387482,1485846.289402008
31,5643265.226650238,1485941.680644989
32,5642556.60654068,1486062.9699249268
33,5641910.222873688,1486137.5104103088
34,5641383.903511047,1486173.1635932922
35,5641033.329219818,1486279.3291168213
36,5640566.3087883,1486385.137878418
37,5640133.519378662,1486463.399860382
38,5639751.408161163,1486538.264453888
39,5639400.701835632,1486619.6967506409
40,5639068.619857788,1486700.1121139526
41,5638725.124649048,1486778.7842903137
42,5638382.289997101,1486843.092037201
43,5638050.150554657,1486893.244819641
44,5637726.60357666,1486933.4822540283
45,5637420.751914978,1486969.1633300781
46,5637135.116340637,1487002.6038589478
47,5636867.561542511,1487034.0231170654
48,5636616.796009064,1487063.5164337158
49,5636382.896244049,1487091.3848495483
