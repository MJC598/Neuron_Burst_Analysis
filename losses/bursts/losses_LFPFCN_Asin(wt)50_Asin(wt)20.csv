epoch,training loss,validation loss
0,0.7409831626301316,0.17265804624184966
1,1.9042398556878837e-06,0.17265733785461634
2,2.8097085974509994e-06,0.17263197374995798
3,6.620194908865673e-06,0.1724930654745549
4,1.5936266039372204e-05,0.17233951424714178
5,1.4817588883067612e-05,0.17185139458160847
6,1.3051304561161048e-05,0.17152906605042517
7,1.1835875177147737e-05,0.1713855795096606
8,1.065841061983347e-05,0.17117892194073647
9,9.8549144449539e-06,0.17094840563368052
10,8.503782429836182e-06,0.17072127980645746
11,8.046067527321676e-06,0.17067049164325
12,6.989170678387002e-06,0.1705752443522215
13,6.351179905508819e-06,0.17053487850353122
14,5.81326662338344e-06,0.17040300939697772
15,5.2835056030473004e-06,0.17029689287301153
16,4.899197339758299e-06,0.17031691188458353
17,4.13815576490173e-06,0.1701818349538371
18,3.881174278692889e-06,0.17021021840628237
19,3.5249341517051835e-06,0.17005269671790302
