{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    !git clone https://github.com/MJC598/Neuron_Burst_Analysis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import scipy.io\n",
    "import random\n",
    "import pandas as pds\n",
    "import time\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FILE = 'losses/losses_rnn_csv.csv'\n",
    "PATH = 'models/baselineRNN.pth'\n",
    "DATA_PATH = 'data/new_bursts.mat'\n",
    "COLAB_PRE = 'Neuron_Burst_Analysis/'\n",
    "if RunningInCOLAB:\n",
    "    LOSS_FILE = COLAB_PRE + LOSS_FILE\n",
    "    PATH = COLAB_PRE + PATH\n",
    "    DATA_PATH = COLAB_PRE + DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Explanations\n",
    "\n",
    "These are 3 regression RNN-based models. In order to change it to a classifier the \n",
    "nn.Linear layers must have their second parameter changed to match the number of \n",
    "expected outputs.\n",
    "\n",
    "* Expected Input Shape: (batch_size, time_sequence, features)\n",
    "\n",
    "* Input_Size - number of features\n",
    "* Hidden_Size - number of connections between the hidden layers\n",
    "* Batch_Size - How many samples you want to push through the network before executing backprop\n",
    "    (this is a hyperparameter that can change how fast or slow a model converges)\n",
    "* Batch_First - Should always be set to True to keep input shape the same\n",
    "* Dropout - Only really does anything with more than 1 layer on the LSTM, RNN, GRU. Useful to help generalize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baselineRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size=1,\n",
    "                 batch_size=1,num_layers=1,batch_first=True,dropout=0.0):\n",
    "        super(baselineRNN, self).__init__()\n",
    "        self.rnn1 = nn.RNN(input_size=input_size,hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,batch_first=batch_first,dropout=dropout)\n",
    "        self.lin = nn.Linear(hidden_size,output_size)\n",
    "        self.h0 = torch.randn(1, batch_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, h_n  = self.rnn1(x,self.h0)\n",
    "\n",
    "        # take last cell output\n",
    "        out = self.lin(x[:, -1, :])\n",
    "\n",
    "        return out\n",
    "\n",
    "class baselineLSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size=1,\n",
    "                 batch_size=1,num_layers=1,batch_first=True,dropout=0.0):\n",
    "        super(baselineLSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size,hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,batch_first=batch_first,dropout=dropout)\n",
    "        self.lin = nn.Linear(hidden_size,output_size)\n",
    "        self.h0 = torch.randn(1, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(1, batch_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (h_n, c_n)  = self.rnn(x,(self.h0,self.c0))\n",
    "\n",
    "        # take last cell output\n",
    "        out = self.lin(x[:, -1, :])\n",
    "\n",
    "        return out\n",
    "\n",
    "class baselineGRU(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size=1,\n",
    "                 batch_size=1,num_layers=1,batch_first=True,dropout=0.0):\n",
    "        super(baselineGRU, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=input_size,hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,batch_first=batch_first,dropout=dropout)\n",
    "        self.lin = nn.Linear(hidden_size,output_size)\n",
    "        self.h0 = torch.randn(1, batch_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(self.h0.shape)\n",
    "        x, h_n  = self.rnn(x,self.h0)\n",
    "\n",
    "        # take last cell output\n",
    "        out = self.lin(x[:, -1, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mat(file_path, type='pre_pn'):\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    duration = []\n",
    "    amp = []\n",
    "    pre_pn = []\n",
    "    pre_itn = []\n",
    "    pre_aff = []\n",
    "    pre_point_exc = []\n",
    "    pre_point_inh = []\n",
    "\n",
    "\n",
    "    for i in range(1, data['info_collect'].shape[0]):\n",
    "        duration.append(data['info_collect'][i][0])\n",
    "        amp.append(data['info_collect'][i][1])\n",
    "        pre_pn.append(data['info_collect'][i][2])\n",
    "        pre_itn.append(data['info_collect'][i][3])\n",
    "        pre_aff.append(data['info_collect'][i][4])\n",
    "        pre_point_exc.append(data['info_collect'][i][5])\n",
    "        pre_point_inh.append(data['info_collect'][i][6])\n",
    "        \n",
    "    \n",
    "\n",
    "    full_data = np.concatenate((pre_pn, pre_itn, pre_aff, pre_point_exc, pre_point_inh), axis=2)\n",
    "    full_labels = np.concatenate((amp, duration), axis=2)\n",
    "    \n",
    "    x = full_labels[:,:,0]\n",
    "    normalized_amp = (x-min(x))/(max(x)-min(x))\n",
    "    full_labels[:,:,0] = normalized_amp\n",
    "    \n",
    "    x = full_labels[:,:,1]\n",
    "    normalized_duration = (x-min(x))/(max(x)-min(x))\n",
    "    full_labels[:,:,1] = normalized_duration\n",
    "    \n",
    "#     print(full_labels)\n",
    "    \n",
    "    random.seed(10)\n",
    "    data_samples = 5440 #5446\n",
    "    k = 4928\n",
    "    full = np.arange(data_samples)\n",
    "    training_indices = np.random.choice(full, size=k, replace=False)\n",
    "    validation_indices = np.delete(full,training_indices)\n",
    "    training_data = full_data[training_indices,:,:]\n",
    "    training_labels = full_labels[training_indices,:,:]\n",
    "    validation_data = full_data[validation_indices,:,:]\n",
    "    validation_labels = full_labels[validation_indices,:,:]\n",
    "    \n",
    "#     print(training_data.shape)\n",
    "#     print(training_labels.shape)\n",
    "#     print(validation_data.shape)\n",
    "#     print(validation_labels.shape)\n",
    "\n",
    "    training_dataset = TensorDataset(torch.Tensor(training_data), torch.Tensor(training_labels))\n",
    "    validation_dataset = TensorDataset(torch.Tensor(validation_data), torch.Tensor(validation_labels))\n",
    "\n",
    "    return training_dataset, validation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Method\n",
    "* Model - Model initialized based on classes above\n",
    "* Save_Filepath - Where you want to save the model to. Should end with a .pt or .pth extension. This is how you are able to load the model later for testing, etc.\n",
    "* training_loader - dataloader iterable with training dataset samples\n",
    "* validation_loader - dataloader iterable with validation dataset samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,save_filepath,training_loader,validation_loader,epochs):\n",
    "    \n",
    "    epochs_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    training_len = len(training_loader.dataset)\n",
    "    validation_len = len(validation_loader.dataset)\n",
    "\n",
    "    #splitting the dataloaders to generalize code\n",
    "    data_loaders = {\"train\": training_loader, \"val\": validation_loader}\n",
    "\n",
    "    \"\"\"\n",
    "    This is your optimizer. It can be changed but Adam is generally used. \n",
    "    Learning rate (alpha in gradient descent) is set to 0.001 but again \n",
    "    can easily be adjusted if you are getting issues\n",
    "\n",
    "    Loss function is set to Mean Squared Error. If you switch to a classifier \n",
    "    I'd recommend switching the loss function to nn.CrossEntropyLoss(), but this \n",
    "    is also something that can be changed if you feel a better loss function would work\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_func = nn.MSELoss()\n",
    "    decay_rate = 0.90 #decay the lr each step to 90% of previous lr\n",
    "    lr_sch = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "\n",
    "    total_start = time.time()\n",
    "\n",
    "    \"\"\"\n",
    "    You can easily adjust the number of epochs trained here by changing the number in the range\n",
    "    \"\"\"\n",
    "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "        start = time.time()\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        temp_loss = 100000000000000.0\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, (x, y) in enumerate(data_loaders[phase]):  \n",
    "                output = model(x)                       \n",
    "                loss = loss_func(torch.squeeze(output), torch.squeeze(y))  \n",
    "                #backprop             \n",
    "                optimizer.zero_grad()           \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()                                      \n",
    "\n",
    "                #calculating total loss\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss\n",
    "                lr_sch.step()\n",
    "            else:\n",
    "                val_loss = running_loss\n",
    "\n",
    "        end = time.time()\n",
    "        # shows total loss\n",
    "        if epoch%10 == 0:\n",
    "            print('[%d, %5d] train loss: %.6f val loss: %.6f' % (epoch + 1, i + 1, train_loss, val_loss))\n",
    "#         print(end - start)\n",
    "        \n",
    "        #saving best model\n",
    "        if val_loss < temp_loss:\n",
    "            torch.save(model, save_filepath)\n",
    "            temp_loss = val_loss\n",
    "        epochs_list.append(epoch)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "    total_end = time.time()\n",
    "#     print(total_end - total_start)\n",
    "    #Creating loss csv\n",
    "    loss_df = pds.DataFrame(\n",
    "        {\n",
    "            'epoch': epochs_list,\n",
    "            'training loss': train_loss_list,\n",
    "            'validation loss': val_loss_list\n",
    "        }\n",
    "    )\n",
    "    # Writing loss csv, change path to whatever you want to name it\n",
    "    loss_df.to_csv(LOSS_FILE, index=None)\n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Scoring\n",
    "* Model - same model as sent to train_model\n",
    "* testing_dataloader - whichever dataloader you want to R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_eval(model, testing_dataloader):\n",
    "    output_list = []\n",
    "    labels_list = []\n",
    "    for i, (x, y) in enumerate(testing_dataloader):      \n",
    "        # Same permute issue we had in training. Basically switching from (batch_size, features, time) \n",
    "        # to (batch_size, time, features) \n",
    "#         x = x.permute(0, 2, 1)\n",
    "        output = model(x) \n",
    "        output_list.append(np.transpose(output.detach().cpu().numpy()))\n",
    "        labels_list.append(np.transpose(y.detach().cpu().numpy()))\n",
    "    output_list = np.transpose(np.hstack(output_list))\n",
    "    labels_list = np.transpose(np.hstack(labels_list)).reshape((-1,2))\n",
    "#     print(output_list.shape)\n",
    "#     print(np.squeeze(labels_list).shape)\n",
    "    print(r2_score(np.squeeze(labels_list), output_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7007f72dfdac4eefa3e03d490ad0c7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    16] train loss: 4.285208 val loss: 0.341639\n",
      "[11,    16] train loss: 2.829123 val loss: 0.299952\n",
      "[21,    16] train loss: 2.766365 val loss: 0.301666\n",
      "[31,    16] train loss: 2.731932 val loss: 0.283532\n",
      "[41,    16] train loss: 2.709183 val loss: 0.285679\n",
      "[51,    16] train loss: 2.701224 val loss: 0.286316\n",
      "[61,    16] train loss: 2.695755 val loss: 0.285188\n",
      "[71,    16] train loss: 2.694445 val loss: 0.285505\n",
      "[81,    16] train loss: 2.693576 val loss: 0.285485\n",
      "[91,    16] train loss: 2.693385 val loss: 0.285477\n",
      "-0.007664372754812909\n",
      "-0.005847642192403302\n"
     ]
    }
   ],
   "source": [
    "input_size = 5\n",
    "hidden_size = 50\n",
    "output_size = 2\n",
    "batch_size = 32\n",
    "num_layers = 1\n",
    "batch_first = True\n",
    "dropout = 0.0\n",
    "epochs = 100\n",
    "# model = baselineLSTM(input_size,hidden_size,output_size,batch_size,num_layers,batch_first,dropout)\n",
    "# model = baselineGRU(input_size,hidden_size,output_size,batch_size,num_layers,batch_first,dropout)\n",
    "model = baselineRNN(input_size,hidden_size,output_size,batch_size,num_layers,batch_first,dropout)\n",
    "training_dataset, validation_dataset = get_data_from_mat(DATA_PATH) #retrieve data function\n",
    "\n",
    "# Turn datasets into iterable dataloaders\n",
    "training_loader = DataLoader(dataset=training_dataset,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset,batch_size=batch_size)\n",
    "\n",
    "training_loss, validation_loss = train_model(model,PATH,training_loader,validation_loader,epochs)\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "r2_score_eval(model, training_loader)\n",
    "r2_score_eval(model, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), training_loss)\n",
    "# plt.plot(range(epochs), validation_loss)\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
