epoch,training loss,validation loss
0,0.12228383213368943,0.12615426210686564
1,0.033065075338527095,0.10995228390675038
2,0.024433705242699943,0.08599105785833672
3,0.0219561247722595,0.06594020506599918
4,0.020987889940442983,0.056911226420197636
5,0.02055104235842009,0.052393156744074076
6,0.020329429396952037,0.048380118678323925
7,0.020192724838125287,0.04552567095379345
8,0.020130085769778816,0.04425711740623228
9,0.020103954870137386,0.04337639902951196
10,0.020091751877771458,0.04272833387949504
11,0.020091644782951334,0.04251993467914872
12,0.020090348833036842,0.04258116375422105
13,0.020092606686375802,0.042591656296281144
14,0.020099577643122757,0.04240946428035386
15,0.02010691432224121,0.04222444928018376
16,0.020110684679821134,0.04212078804266639
17,0.02011135464636027,0.04209725096006878
18,0.02010965863155434,0.042131208727369085
19,0.020106193212996004,0.042182000062894076
