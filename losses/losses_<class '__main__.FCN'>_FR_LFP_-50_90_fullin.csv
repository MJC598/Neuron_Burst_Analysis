epoch,training loss,validation loss
0,1485126.761379242,349877.0894012451
1,1279935.4198417664,329591.9453125
2,1233002.385017395,320474.5157032013
3,1205740.335439682,306785.2465171814
4,1184384.3178844452,303602.50517463684
5,1178571.1107559204,300057.9735622406
6,1170386.6822490692,299253.280544281
7,1154320.3331317902,302292.10565567017
8,1155550.4188423157,294034.5132255554
9,1144645.7607212067,293304.8357372284
10,1137111.8430900574,297198.4041366577
11,1129162.2899894714,293232.828294754
12,1127146.4492092133,289313.0312862396
13,1113919.937740326,288421.2817249298
14,1112408.2932071686,281993.6587276459
15,1104314.884141922,283026.31872940063
16,1101648.656578064,281138.0510444641
17,1098610.0943279266,282177.88909721375
18,1092688.2419662476,280260.3858795166
19,1090079.4246444702,280493.58683395386
20,1090369.7757263184,279568.8989276886
21,1088639.4951171875,277892.095079422
22,1082492.2587451935,278429.64940452576
23,1075152.618013382,275929.9192237854
24,1071718.74092865,275158.81556510925
25,1068072.1379814148,275676.26292800903
26,1068115.0849552155,273629.8412399292
27,1064275.2969112396,275047.562128067
28,1063155.9173812866,271595.8715133667
29,1060054.0222263336,271945.59416389465
30,1057564.9382209778,271766.507270813
31,1057687.0363178253,271303.7451324463
32,1054938.533744812,270940.899766922
33,1053298.814315796,270489.93247795105
34,1052155.546157837,270397.07408714294
35,1051242.0021343231,269425.058259964
36,1048285.9050254822,269862.8498840332
37,1047331.6987075806,268597.7635707855
38,1045010.1050796509,268940.1814651489
39,1044050.0383834839,268117.1442813873
40,1042434.2356014252,267581.01383399963
41,1041416.9713840485,266932.9920864105
42,1040851.4791564941,267071.85594177246
43,1040005.1514148712,267223.7147407532
44,1038839.6439056396,266275.4260215759
45,1037314.0457839966,266929.19692993164
46,1036474.5308074951,266018.7996330261
47,1035992.8729038239,266516.8301486969
48,1035634.3893051147,265871.235994339
49,1034358.6950569153,265814.82580184937
