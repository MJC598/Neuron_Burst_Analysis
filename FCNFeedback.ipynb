{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    !git clone https://github.com/MJC598/Neuron_Burst_Analysis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fad1e8286d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.io\n",
    "import random\n",
    "import time\n",
    "import pandas as pds\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fully Connected Network](graphs/fullyConnectedNetwork.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FCN,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        out = self.fc2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRONT_TIME = -50\n",
    "BACK_TIME = 40\n",
    "T_START = 50+FRONT_TIME\n",
    "T_END = 'Variable'\n",
    "MODEL = FCN\n",
    "OUTPUT = 'FR_LFP'\n",
    "LOSS_FILE = ('losses/bursts/losses_' + str(MODEL) + \n",
    "             '_' + OUTPUT + '_' + str(FRONT_TIME) + \n",
    "             '_' + str(T_END) + '_30ms_avgaff_and_fr.csv')\n",
    "PATH = ('models/bursts/' + str(MODEL) + '_' + OUTPUT + \n",
    "        '_' + str(FRONT_TIME) + '_' + str(T_END) + \n",
    "        '_30ms_avgaff_and_fr.pth')\n",
    "# PATH = 'models/<class \\'__main__.FCN\\'>_FR_LFP_-50_90_full.pth'\n",
    "\n",
    "DATA_PATH = 'data/bursts/burst_separatePNITNv2.mat'\n",
    "COLAB_PRE = 'Neuron_Burst_Analysis/'\n",
    "if RunningInCOLAB:\n",
    "    LOSS_FILE = COLAB_PRE + LOSS_FILE\n",
    "    PATH = COLAB_PRE + PATH\n",
    "    DATA_PATH = COLAB_PRE + DATA_PATH\n",
    "\n",
    "# Specific Model Parameters\n",
    "input_features = 9\n",
    "previous_time = 10\n",
    "input_size = input_features * previous_time\n",
    "hidden_size = 95\n",
    "output_size = 3\n",
    "batch_size = 32\n",
    "num_layers = 1\n",
    "batch_first = True\n",
    "dropout = 0.0\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data From Matlab File\n",
    "\n",
    "Read in Matlab info and Average over sliding window of size 3 PN Afferent and PN Firing Rate. \n",
    "Variables:\n",
    "$$\n",
    "x = \\text{PN Firing Rate}\\\\\n",
    "y = \\text{ITN Firing Rate}\\\\\n",
    "z = \\text{Local Field Potential}\\\\\n",
    "e_{1} = \\text{PN Afferent}\\\\\n",
    "e_{2} = \\text{ITN Afferent}\\\\\n",
    "e_{3} = \\text{PN Excitatory Point Conductance}\\\\\n",
    "e_{4} = \\text{ITN Excitatory Point Conductance}\\\\\n",
    "e_{5} = \\text{PN Inhibitory Point Conductance}\\\\\n",
    "e_{6} = \\text{ITN Inhibitory Point Conductance}\\\\\n",
    "t = \\text{Timestep}\\\\\n",
    "m = \\text{Number of Previous Timesteps}\\\\\n",
    "N = \\text{Number of Samples}\\\\\n",
    "n = \\text{Individual Sample}\\\\\n",
    "f = \\text{Number of Features}\\\\\n",
    "\\omega(n) = \\text{Time Sequence of Sample n}\\\\\n",
    "$$\n",
    "\n",
    "Sliding Window:\n",
    "$$\n",
    "x_{t} = \n",
    "\\begin{cases} \n",
    "    \\frac{1}{3}\\sum_{i=0}^{2}x_{t+i} & \\text{if } t \\geq 2\\\\\n",
    "    x_{t} & otherwise\\\\\n",
    "\\end{cases}\\\\\n",
    "e_{1,t} = \n",
    "\\begin{cases}\n",
    "    \\frac{1}{3}\\sum_{i=0}^{2}e_{1,t+i}& \\text{if } t \\geq 2\\\\\n",
    "    e_{1,t} & otherwise\\\\\n",
    "\\end{cases}\\\\\n",
    "$$\n",
    "\n",
    "Data $\\text{size} = (N \\times 1) , n = (\\omega(n) \\times f)$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{t} & y_{t} & e_{1, t} & e_{2, t} & e_{3, t} & e_{4, t} & e_{5, t} & e_{6, t} & z_{t}\\\\\n",
    "x_{t+1} & y_{t+1} & e_{1, t+1} & e_{2, t+1} & e_{3, t+1} & e_{4, t+1} & e_{5, t+1} & e_{6, t+1} & z_{t+1}\\\\\n",
    "...\\\\\n",
    "x_{t+\\omega(n)} & y_{t+\\omega(n)} & e_{1, t+\\omega(n)} & e_{2, t+\\omega(n)} & e_{3, t+\\omega(n)} & e_{4, t+\\omega(n)} & e_{5, t+\\omega(n)} & e_{6, t+\\omega(n)} & z_{t+\\omega(n)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Label $\\text{size} = (N \\times 1) , n = (\\omega(n) \\times 3)$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{t} & y_{t} & z_{t}\\\\\n",
    "x_{t+1} & y_{t+1} & z_{t+1}\\\\\n",
    "...\\\\\n",
    "x_{t+\\omega(n)} & y_{t+\\omega(n)} & z_{t+\\omega(n)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Building Inputs $\\text{size} = ((\\sum_{n=0}^{N}\\omega(n) - m - 1) \\times (f*m))$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{0,t} & y_{0,t} & e_{1,0,t} & e_{2,0,t} & e_{3,0,t} & e_{4,0,t} & e_{5,0,t} & e_{6,0,t} & z_{0,t} & x_{0,t+1} & ... & z_{0,t+m}\\\\\n",
    "x_{0,t+1} & y_{0,t+1} & e_{1,0,t+1} & e_{2,0,t+1} & e_{3,0,t+1} & e_{4,0,t+1} & e_{5,0,t+1} & e_{6,0,t+1} & z_{0,t+1} & x_{0,t+2} & ... & z_{0,t+m+1}\\\\\n",
    "...\\\\\n",
    "x_{0,\\omega(0)-m-1} & y_{0,\\omega(0)-m-1} & e_{1,0,\\omega(0)-m-1} & e_{2,0,\\omega(0)-m-1} & e_{3,0,\\omega(0)-m-1} & e_{4,0,\\omega(0)-m-1} & e_{5,0,\\omega(0)-m-1} & e_{6,0,\\omega(0)-m-1} & z_{0,\\omega(0)-m-1} & x_{0,\\omega(0)-m} & ... & z_{0,\\omega(0)-1}\\\\\n",
    "...\\\\\n",
    "x_{N,t} & y_{N,t} & e_{1,N,t} & e_{2,N,t} & e_{3,N,t} & e_{4,N,t} & e_{5,N,t} & e_{6,N,t} & z_{N,t} & x_{N,t+1} & ... & z_{N,t+m}\\\\\n",
    "x_{N,t+1} & y_{N,t+1} & e_{1,N,t+1} & e_{2,N,t+1} & e_{3,N,t+1} & e_{4,N,t+1} & e_{5,N,t+1} & e_{6,N,t+1} & z_{N,t+1} & x_{N,t+2} & ... & z_{N,t+m+1}\\\\\n",
    "...\\\\\n",
    "x_{N,\\omega(N)-m-1} & y_{N,\\omega(N)-m-1} & e_{1,N,\\omega(N)-m-1} & e_{2,N,\\omega(N)-m-1} & e_{3,N,\\omega(N)-m-1} & e_{4,N,\\omega(N)-m-1} & e_{5,N,\\omega(N)-m-1} & e_{6,N,\\omega(N)-m-1} & z_{N,\\omega(N)-m-1} & x_{N,\\omega(N)-m} & ... & z_{N,\\omega(N)-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Building Labels $\\text{size} = ((\\sum_{n=0}^{N}\\omega(n) - m - 1) \\times 3)$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{0,t+m+1} & y_{0,t+m+1} & z_{0,t+m+1}\\\\\n",
    "x_{0,t+m+2} & y_{0,t+m+2} & z_{0,t+m+2}\\\\\n",
    "...\\\\\n",
    "x_{0,\\omega(0)} & y_{0,\\omega(0)} & z_{0,\\omega(0)}\\\\\n",
    "...\\\\\n",
    "x_{N,t+m+1} & y_{N,t+m+1} & z_{N,t+m+1}\\\\\n",
    "x_{N,t+m+2} & y_{N,t+m+2} & z_{N,t+m+2}\\\\\n",
    "...\\\\\n",
    "x_{N,\\omega(N)} & y_{N,\\omega(N)} & z_{N,\\omega(N)}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.TensorDataset at 0x7face44c1130>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x7face44c1fd0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_data_from_mat(file_path, output_index=None, type='pre_pn'):\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "\n",
    "    full_labels = []\n",
    "    full_data = []\n",
    "    \n",
    "#     print(data['info_collect'][0])\n",
    "    for i in range(1, data['info_collect'].shape[0]):\n",
    "        arr = data['info_collect'][i]\n",
    "        \n",
    "        pnfr = np.row_stack((arr[2], arr[11]))\n",
    "        pnaff = np.row_stack((arr[4], arr[13]))\n",
    "        \n",
    "        for j in range(pnfr.shape[0]):\n",
    "            if j != 0 and j != 1:\n",
    "                pnfr[j,:] = (pnfr[j-2,:] + pnfr[j-1,:] + pnfr[j,:])/3\n",
    "                pnaff[j,:] = (pnaff[j-2,:] + pnaff[j-1,:] + pnaff[j,:])/3\n",
    "            else:\n",
    "                pnfr[j,:] = pnfr[j,:]\n",
    "                pnaff[j,:] = pnaff[j,:]\n",
    "        \n",
    "        full_labels.append(np.column_stack((pnfr, \n",
    "                                            np.row_stack((arr[3], arr[12])), \n",
    "                                            np.row_stack((arr[10], arr[19])))))\n",
    "        \n",
    "        full_data.append(np.column_stack((pnfr, \n",
    "                                          np.row_stack((arr[3], arr[12])), \n",
    "                                          pnaff, \n",
    "                                          np.row_stack((arr[5], arr[14])), \n",
    "                                          np.row_stack((arr[6], arr[15])), \n",
    "                                          np.row_stack((arr[7], arr[16])), \n",
    "                                          np.row_stack((arr[8], arr[17])), \n",
    "                                          np.row_stack((arr[9], arr[18])), \n",
    "                                          np.row_stack((arr[10], arr[19])))))\n",
    "\n",
    "#     print(full_data[0].shape)\n",
    "    full_data = np.asarray(full_data,dtype=object)\n",
    "    full_labels = np.asarray(full_labels,dtype=object)\n",
    "    \n",
    "    random.seed(10)\n",
    "    data_samples = 5472 #5498 \n",
    "    k = 4352\n",
    "    \n",
    "    lag = 1\n",
    "    front_offset = 11\n",
    "#     print(full_data[0].shape)\n",
    "    training_data = full_data[:k] \n",
    "    validation_data = full_data[k:data_samples]\n",
    "    training_labels = full_labels[:k]\n",
    "    validation_labels = full_labels[k:data_samples]\n",
    "    \n",
    "    td = [] \n",
    "    tl = []\n",
    "    vd = []\n",
    "    vl = []\n",
    "    for i, d in enumerate(training_data):\n",
    "        sample = d[:-1,:]\n",
    "        label = training_labels[i][1:,:]\n",
    "        for j in range(sample.shape[0]-previous_time):\n",
    "            t = sample[j:j+previous_time,:]\n",
    "            td.append(t.reshape((1,-1)))\n",
    "            t2 = label[j+previous_time,:]\n",
    "            tl.append(t2.reshape((1,-1)))\n",
    "    td = np.vstack(td)\n",
    "    tl = np.vstack(tl)\n",
    "    \n",
    "    \n",
    "    for i, d in enumerate(validation_data):\n",
    "        sample = d[:-1,:]\n",
    "        label = validation_labels[i][1:,:]\n",
    "        for j in range(sample.shape[0]-previous_time):\n",
    "            t = sample[j:j+previous_time,:]\n",
    "            vd.append(t.reshape((1,-1)))\n",
    "            t2 = label[j+previous_time,:]\n",
    "            vl.append(t2.reshape((1,-1)))\n",
    "    vd = np.vstack(vd)\n",
    "    vl = np.vstack(vl)\n",
    "\n",
    "    training_dataset = TensorDataset(torch.Tensor(td), torch.Tensor(tl))\n",
    "    validation_dataset = TensorDataset(torch.Tensor(vd), torch.Tensor(vl))\n",
    "\n",
    "    return training_dataset, validation_dataset\n",
    "# get_full_data_from_mat(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,save_filepath,training_loader,validation_loader,epochs,device):\n",
    "    epochs_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    training_len = len(training_loader.dataset)\n",
    "    validation_len = len(validation_loader.dataset)\n",
    "    \n",
    "#     feedback_arr = torch.zeros(batch_size, 90)\n",
    "    \n",
    "    #splitting the dataloaders to generalize code\n",
    "    data_loaders = {\"train\": training_loader, \"val\": validation_loader}\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_func = nn.MSELoss()\n",
    "#     loss_func = nn.L1Loss()\n",
    "    decay_rate = 0.93 #decay the lr each step to 93% of previous lr\n",
    "    lr_sch = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "\n",
    "    total_start = time.time()\n",
    "\n",
    "    \"\"\"\n",
    "    You can easily adjust the number of epochs trained here by changing the number in the range\n",
    "    \"\"\"\n",
    "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "        start = time.time()\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        temp_loss = 100000000000000.0\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, (x, y) in enumerate(data_loaders[phase]):\n",
    "                x = x.to(device)\n",
    "                output = model(x)\n",
    "                y = y.to(device)\n",
    "                loss = loss_func(torch.squeeze(output), torch.squeeze(y)) \n",
    "                #backprop             \n",
    "                optimizer.zero_grad()           \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()                                      \n",
    "\n",
    "                #calculating total loss\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss\n",
    "                lr_sch.step()\n",
    "            else:\n",
    "                val_loss = running_loss\n",
    "\n",
    "        end = time.time()\n",
    "        # shows total loss\n",
    "        if epoch%5 == 0:\n",
    "            print('[%d, %5d] train loss: %.6f val loss: %.6f' % (epoch + 1, i + 1, train_loss, val_loss))\n",
    "#         print(end - start)\n",
    "        \n",
    "        #saving best model\n",
    "        if val_loss < temp_loss:\n",
    "            torch.save(model, save_filepath)\n",
    "            temp_loss = val_loss\n",
    "        epochs_list.append(epoch)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "    total_end = time.time()\n",
    "#     print(total_end - total_start)\n",
    "    #Creating loss csv\n",
    "    loss_df = pds.DataFrame(\n",
    "        {\n",
    "            'epoch': epochs_list,\n",
    "            'training loss': train_loss_list,\n",
    "            'validation loss': val_loss_list\n",
    "        }\n",
    "    )\n",
    "    # Writing loss csv, change path to whatever you want to name it\n",
    "    \n",
    "    loss_df.to_csv(LOSS_FILE, index=None)\n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5f44bb4ed144889a017075ca1a8da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  6125] train loss: 3048557.341652 val loss: 737220.934910\n",
      "[6,  6125] train loss: 2558882.646463 val loss: 661238.938334\n",
      "[11,  6125] train loss: 2446869.373968 val loss: 644653.442577\n",
      "[16,  6125] train loss: 2402438.409304 val loss: 634241.124636\n",
      "[21,  6125] train loss: 2359269.151180 val loss: 615347.841049\n",
      "[26,  6125] train loss: 2333556.103411 val loss: 605548.642773\n",
      "[31,  6125] train loss: 2300620.510614 val loss: 596472.856260\n",
      "[36,  6125] train loss: 2290563.177565 val loss: 599856.876688\n",
      "[41,  6125] train loss: 2274732.108633 val loss: 593338.082266\n",
      "[46,  6125] train loss: 2267168.187887 val loss: 593289.669682\n"
     ]
    }
   ],
   "source": [
    "model1 = MODEL(input_size,hidden_size,output_size)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1.to(device)\n",
    "\n",
    "f_tr, f_va = get_full_data_from_mat(DATA_PATH)\n",
    "\n",
    "# Turn datasets into iterable dataloaders\n",
    "f_training_loader = DataLoader(dataset=f_tr,batch_size=batch_size)\n",
    "f_validation_loader = DataLoader(dataset=f_va,batch_size=batch_size)\n",
    "\n",
    "pnfr_training_loss, pnfr_validation_loss = train_model(model1,PATH,f_training_loader,\n",
    "                                                       f_validation_loader,epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_full_score_eval(model, testing_dataloader, k=None):\n",
    "    output_list = []\n",
    "    labels_list = []\n",
    "    temp_list = []\n",
    "    for i, (x, y) in enumerate(testing_dataloader):\n",
    "        output = model(x)         \n",
    "        output_list.append(output.detach().cpu().numpy())\n",
    "        labels_list.append(y.detach().cpu().numpy())\n",
    "        if k != None and i == k-1:\n",
    "            break\n",
    "#     print(\"Output list size: {}\".format(len(output_list)))\n",
    "#     print(output_list[0].shape)\n",
    "    output_list = np.concatenate(output_list, axis=0)\n",
    "    labels_list = np.concatenate(labels_list, axis=0)\n",
    "#     print(output_list.shape)\n",
    "#     print(labels_list.shape)\n",
    "    print(r2_score(labels_list, output_list))\n",
    "    return output_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask\n",
    "Variables:\n",
    "$$\n",
    "x = \\text{PN Firing Rate}\\\\\n",
    "y = \\text{ITN Firing Rate}\\\\\n",
    "z = \\text{Local Field Potential}\\\\\n",
    "t = \\text{Timestep}\\\\\n",
    "m = \\text{Number of Previous Timesteps}\\\\\n",
    "e_{x} = \\text{External Input}\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Output Array:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{n,t+m} & y_{n,t+m} & z_{n,t+m}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Feedback Array: \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{n,t-1} & y_{n,t-1} & z_{n,t-1} & x_{n,t} & ... & z_{n,t+m-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Replace index 0, 1, 2 with Output Array and Roll\n",
    "\n",
    "Rolled Feedback Array: \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{n,t} & y_{n,t} & z_{n,t} & x_{n,t+1} & ... & z_{n,t+m}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Input Array:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{n,t} & y_{n,t} & e_{1,n,t} & e_{2,n,t} & e_{3,n,t} & e_{4,n,t} & e_{5,n,t} & e_{6,n,t} & z_{n,t} & x_{n,t+1} & ... & z_{n,t+m}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "New Output:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{n,t+m+1} & y_{n,t+m+1} & z_{n,t+m+1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_eval(model, testing_dataloader, start=10, k=None):\n",
    "    output_list = []\n",
    "    labels_list = []\n",
    "    temp_list = []\n",
    "    mask = [True, True, False, False, False, False, False, False, True]\n",
    "    mask = list(np.tile(mask, previous_time))\n",
    "    feedback_arr = torch.zeros(1, 3*previous_time)\n",
    "    for i, (x, y) in enumerate(testing_dataloader):\n",
    "        x2 = x.numpy().copy()\n",
    "        if i >= start:\n",
    "            x2[:,mask] = feedback_arr.numpy()\n",
    "        output = model(torch.Tensor(x2))     \n",
    "        \n",
    "        feedback_arr = torch.roll(feedback_arr, -3, 1)\n",
    "        feedback_arr[:,0] = output[:,0].detach()\n",
    "        feedback_arr[:,1] = output[:,1].detach()\n",
    "        feedback_arr[:,2] = output[:,2].detach()\n",
    "        feedback_arr.detach()\n",
    "        \n",
    "        output_list.append(output.detach().cpu().numpy())\n",
    "        labels_list.append(y.detach().cpu().numpy())\n",
    "        if k != None and i == k-1:\n",
    "            break\n",
    "#     print(\"Output list size: {}\".format(len(output_list)))\n",
    "#     print(output_list[0].shape)\n",
    "    output_list = np.concatenate(output_list, axis=0)\n",
    "    labels_list = np.concatenate(labels_list, axis=0)\n",
    "    print(r2_score(labels_list, output_list))\n",
    "    return output_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4841068861722142\n",
      "0.48792639523401365\n",
      "(6560, 3)\n",
      "(6560, 3)\n",
      "0.4060221308260064\n",
      "0.49388899349136595\n",
      "(205, 3)\n",
      "(205, 3)\n"
     ]
    }
   ],
   "source": [
    "model1 = torch.load(PATH)\n",
    "model1.eval()\n",
    "\n",
    "# training_dataset, validation_dataset = get_data_from_mat(DATA_PATH)\n",
    "# training_loader = DataLoader(dataset=training_dataset,batch_size=1)\n",
    "# validation_loader = DataLoader(dataset=validation_dataset,batch_size=1)\n",
    "\n",
    "training_loader = DataLoader(dataset=f_tr,batch_size=1)\n",
    "validation_loader = DataLoader(dataset=f_va,batch_size=1)\n",
    "\n",
    "start = 200\n",
    "k = 5\n",
    "end= start + k\n",
    "\n",
    "model1.to('cpu')\n",
    "\n",
    "ft_output_list, ft_labels_list = r2_full_score_eval(model1, f_training_loader,end)\n",
    "fv_output_list, fv_labels_list = r2_full_score_eval(model1, f_validation_loader,end)\n",
    "print(ft_output_list.shape)\n",
    "print(ft_labels_list.shape)\n",
    "\n",
    "t_output_list, t_labels_list = r2_score_eval(model1, training_loader,start,end)\n",
    "v_output_list, v_labels_list = r2_score_eval(model1, validation_loader,start,end)\n",
    "print(t_output_list.shape)\n",
    "print(t_labels_list.shape)\n",
    "# print(t_labels_list[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c119dcfefbc94c83b30e18a9be320db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7face432c070>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "fig.tight_layout()\n",
    "# ax[0,0].plot(range(epochs), pnfr_training_loss)\n",
    "# ax[0,0].set_title('Validation Loss')\n",
    "# ax[0,0].set_ylabel('Loss')\n",
    "# ax[0,0].set_xlabel('Epoch')\n",
    "\n",
    "# ax[0,1].plot(range(epochs), pnfr_validation_loss)\n",
    "# ax[0,1].set_title('Training Loss')\n",
    "# ax[0,1].set_ylabel('Loss')\n",
    "# ax[0,1].set_xlabel('Epoch')\n",
    "\n",
    "\n",
    "ax[0,0].plot(np.arange(start-10,end), v_labels_list[start-10:end,0], color='blue', label='Labels')\n",
    "ax[0,0].plot(np.arange(start-10,end), v_output_list[start-10:end,0], color='red',label='Internal Loop')\n",
    "ax[0,0].plot(np.arange(start-10,end), fv_output_list[start-10:end,0], color='green',label='Training')\n",
    "ax[0,0].set_title('Validation PN FR')\n",
    "ax[0,0].set_ylabel('PN FR')\n",
    "ax[0,0].set_xlabel('Time and Sample')\n",
    "# ax[0,0].legend()\n",
    "\n",
    "ax[0,1].plot(np.arange(start-10,end), t_labels_list[start-10:end,0], color='blue',label='Labels')\n",
    "ax[0,1].plot(np.arange(start-10,end), t_output_list[start-10:end,0], color='red',label='Internal Loop')\n",
    "ax[0,1].plot(np.arange(start-10,end), ft_output_list[start-10:end,0], color='green',label='Training')\n",
    "ax[0,1].set_title('Training PN FR')\n",
    "ax[0,1].set_ylabel('PN FR')\n",
    "ax[0,1].set_xlabel('Time')\n",
    "# ax[0,1].legend()\n",
    "\n",
    "ax[1,0].plot(np.arange(start-10,end), v_labels_list[start-10:end,1], color='blue',label='Labels')\n",
    "ax[1,0].plot(np.arange(start-10,end), v_output_list[start-10:end,1], color='red',label='Internal Loop')\n",
    "ax[1,0].plot(np.arange(start-10,end), fv_output_list[start-10:end,1], color='green',label='Training')\n",
    "ax[1,0].set_title('Validation ITN FR')\n",
    "ax[1,0].set_ylabel('ITN FR')\n",
    "ax[1,0].set_xlabel('Time')\n",
    "# ax[1,0].legend()\n",
    "\n",
    "ax[1,1].plot(np.arange(start-10,end), t_labels_list[start-10:end,1], color='blue',label='Labels')\n",
    "ax[1,1].plot(np.arange(start-10,end), t_output_list[start-10:end,1], color='red',label='Internal Loop')\n",
    "ax[1,1].plot(np.arange(start-10,end), ft_output_list[start-10:end,1], color='green',label='Training')\n",
    "ax[1,1].set_title('Training ITN FR')\n",
    "ax[1,1].set_ylabel('ITN FR')\n",
    "ax[1,1].set_xlabel('Time')\n",
    "# ax[1,1].legend()\n",
    "\n",
    "ax[2,0].plot(np.arange(start-10,end), v_labels_list[start-10:end,2], color='blue',label='Labels')\n",
    "ax[2,0].plot(np.arange(start-10,end), v_output_list[start-10:end,2], color='red',label='Internal Loop')\n",
    "ax[2,0].plot(np.arange(start-10,end), fv_output_list[start-10:end,2], color='green',label='Training')\n",
    "ax[2,0].set_title('Validation LFP')\n",
    "ax[2,0].set_ylabel('LFP')\n",
    "ax[2,0].set_xlabel('Time')\n",
    "# ax[2,0].legend()\n",
    "\n",
    "ax[2,1].plot(np.arange(start-10,end), t_labels_list[start-10:end,2], color='blue',label='Labels')\n",
    "ax[2,1].plot(np.arange(start-10,end), t_output_list[start-10:end,2], color='red',label='Internal Loop')\n",
    "ax[2,1].plot(np.arange(start-10,end), ft_output_list[start-10:end,2], color='green',label='Training')\n",
    "ax[2,1].set_title('Training LFP')\n",
    "ax[2,1].set_ylabel('LFP')\n",
    "ax[2,1].set_xlabel('Time')\n",
    "ax[2,1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
