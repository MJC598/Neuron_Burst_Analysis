epoch,training loss,validation loss
0,2.2621585428132676,0.1768979195621796
1,1.5915224438649602,0.1768932113191113
2,1.5917989008594304,0.17699530924437568
3,1.5921146076289006,0.1771756744128652
4,1.5922285450506024,0.1771885881316848
5,1.5922141061746515,0.17717445304151624
6,1.5921777356415987,0.17714978102594614
7,1.592131344776135,0.1771205264958553
8,1.5920926707331091,0.17708890384528786
9,1.5920540806255303,0.17705713241593912
10,1.592017071438022,0.1770270866691135
11,1.591981584962923,0.17700005642836913
12,1.5919476136332378,0.1769766952493228
13,1.5919151774724014,0.17695711960550398
14,1.5918842998798937,0.17694107920397073
15,1.5918549919733778,0.1769281507586129
16,1.5918272419949062,0.17691788246156648
17,1.5918010026216507,0.17690987727837637
18,1.591776189103257,0.17690381238935515
19,1.5917527035926469,0.1768994180019945
