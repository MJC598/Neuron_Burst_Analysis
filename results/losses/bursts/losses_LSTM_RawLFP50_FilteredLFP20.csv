epoch,training loss,validation loss
0,0.2419038961706974,0.013227820927568246
1,0.11748539070322295,0.013179284567740979
2,0.11680852674180642,0.013160600283299573
3,0.11611097759305267,0.012956440150446724
4,0.1152894628503418,0.012795007805834757
5,0.11451570195276872,0.012636481154913781
6,0.11388964038633276,0.012529374504083535
7,0.11339789806879708,0.012484133669204311
8,0.112945192893676,0.012445890464732656
9,0.11249224021594273,0.01240980301372474
10,0.11204996663582278,0.012369719861453632
11,0.11160022998956265,0.012333508017036365
12,0.1111215984201408,0.012304984320508083
13,0.11061322403111262,0.012276962639589328
14,0.11009084245597478,0.012252740856638411
15,0.10960617246018955,0.012240309471962973
16,0.1092108409247885,0.012233087811182486
17,0.10890143415599596,0.012212184039526619
18,0.10864783178840298,0.012171306858363096
19,0.10842922921801801,0.012124499851779547
