epoch,training loss,validation loss
0,3.8338927421718836,0.16085560305509716
1,1.4408200939651579,0.16078244696836919
2,1.4407818348845467,0.1607824441161938
3,1.4407825249363668,0.16078254458261654
4,1.440783818718046,0.16078374383505434
5,1.440786874620244,0.16078529320657253
6,1.4407897864002734,0.16078516218112782
7,1.440792464709375,0.1607847873819992
8,1.440792401903309,0.16078458278207108
9,1.4407911721500568,0.1607843671226874
10,1.4407889498397708,0.1607838846393861
11,1.4407851242576726,0.16078292456222698
12,1.4407786368392408,0.16078182472847402
13,1.4407667079940438,0.16078067349735647
14,1.440754318551626,0.16077919013332576
15,1.440741516300477,0.1607776401215233
16,1.4407296004937962,0.16077668487560004
17,1.4407222287263721,0.16077615175163373
18,1.4407185285817832,0.1607757403398864
19,1.4407162053394131,0.16077539569232613
20,1.4407143290154636,0.16077509126625955
21,1.4407126771402545,0.16077482339460403
22,1.440711209201254,0.1607745960354805
23,1.4407099041272886,0.16077440860681236
24,1.4407087588915601,0.16077425837283954
