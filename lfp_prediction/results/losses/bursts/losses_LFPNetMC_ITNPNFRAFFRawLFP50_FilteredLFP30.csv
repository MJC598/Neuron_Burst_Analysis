epoch,training loss,validation loss
0,2.4293346848135116,0.029126006957085337
1,0.24601844613061985,0.02572412067092955
2,0.22860173661320005,0.025185374943248462
3,0.22195411302527646,0.024462031375151128
4,0.21745626682968577,0.024603978752566036
5,0.21500421083328547,0.02430250257748412
6,0.2138291199298692,0.024054944478848483
7,0.21271514808177017,0.023885505615908187
8,0.21180960254423553,0.023940469574881718
9,0.21123177441040752,0.02376050830935128
10,0.21064383356861072,0.023929994626087137
11,0.21009564563428285,0.024113021936500445
12,0.20937581836915342,0.02356380816490855
13,0.20892699058458675,0.02362248790450394
14,0.2086431417701533,0.02365239500795724
15,0.2082511278349557,0.023549514458863996
16,0.20771142068406334,0.02342765065986896
17,0.20732387641328387,0.023345307665294968
18,0.2068902284372598,0.023273550075828098
19,0.2063907163537806,0.023219844930281397
