epoch,training loss,validation loss
0,1.161508270073682,0.12209585832897574
1,1.1008170844288543,0.12194439413724467
2,1.0975574386538938,0.12162729859119281
3,1.0927314326982014,0.12074047885835171
4,1.0676990089123137,0.1167111758259125
5,1.0443691394175403,0.11531507381005213
6,1.0298679128754884,0.11439255537698045
7,1.0201570892240852,0.11394046506029554
8,1.0153906420164276,0.11330987024120986
9,1.0121835925674532,0.11270960816182196
10,1.009763309295522,0.11225201791967265
11,1.007805278612068,0.11190277311834507
12,1.0061326449213084,0.11161061277380213
13,1.0046505763602909,0.11135570172336884
14,1.003308508428745,0.11114350950811058
15,1.0020913741609547,0.11098073550965637
16,1.001005737023661,0.11086388980038464
17,1.0000555995793547,0.1107819345779717
18,0.9992310844827443,0.11072143545607105
19,0.9985129719425458,0.11067195126088336
