epoch,training loss,validation loss
0,128.44454148458317,0.8810955695807934
1,4.384655813104473,0.3014213457936421
2,2.2390457168221474,0.21594638854730874
3,1.779594925174024,0.18469670281047001
4,1.5790512002422474,0.16952826391207054
5,1.4866675405064598,0.16332797112409025
6,1.453678636054974,0.16151279874611646
7,1.4446592890308239,0.16101074777543545
8,1.441881176782772,0.16083324130158871
9,1.4409863761393353,0.1607898895163089
10,1.4408083634334616,0.16078313562320545
11,1.4407807431416586,0.1607818381744437
12,1.4407746651559137,0.16078164224745706
13,1.4407727483194321,0.160781680024229
14,1.4407717766007408,0.1607816506875679
15,1.4407706970232539,0.1607814609305933
16,1.4407685037585907,0.1607807864784263
17,1.440762372862082,0.16077953216154128
18,1.4407465591211803,0.1607779479236342
19,1.4407278893631883,0.16077740787295625
20,1.4407206806936301,0.16077680623857304
21,1.4407187089673243,0.1607762661878951
22,1.4407179046538658,0.16077603009762242
23,1.4407174697262235,0.16077592055080459
24,1.440717194287572,0.16077581193530932
