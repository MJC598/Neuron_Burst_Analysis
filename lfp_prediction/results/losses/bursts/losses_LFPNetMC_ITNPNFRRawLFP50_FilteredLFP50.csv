epoch,training loss,validation loss
0,1.428927351895254,0.15262800332857296
1,1.3609504780033603,0.1518610295606777
2,1.355939332046546,0.1515855126781389
3,1.352383482560981,0.15124473912874237
4,1.349801791831851,0.15100986353354529
5,1.3471984232310206,0.15089857572456822
6,1.3450221061357297,0.1508119507925585
7,1.3432234425563365,0.15070240962086245
8,1.3415768153499812,0.1507114987471141
9,1.3402225156896748,0.1506268146331422
10,1.3389418199076317,0.1504836836247705
11,1.3378456813516095,0.15043296566000208
12,1.3369223938207142,0.1504343818523921
13,1.3360640984610654,0.15037316677626222
14,1.3353033842868172,0.15037814452080056
15,1.3345473293447867,0.15034936351003125
16,1.3338536414667033,0.15032193181104958
17,1.3332393560558558,0.1503105154260993
18,1.3326001721434295,0.1503102062852122
19,1.331912902474869,0.15029508678708225
